{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This version is trained on predictions.csv, which contains LaFleur et al.'s base data. For X data, it onehot encodes base pairs in each element and appeneds them to a 2 dimensional array. It pads each element so that each element is the same length. This was a design decision that we changed later. The y data is the 'Observed log(TX/Txref)' which is normalized using sklearn's MinMaxScaler (from 0, high expression to 1, low expression).\n",
    "\n",
    "The model uses a 3x3 kernal and no early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "\n",
    "df = pd.read_csv('../predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the y values\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df['Normalized Observed'] = MinMaxScaler().fit_transform(df[['Observed log(TX/Txref)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to onehot encode the input (x) sequences\n",
    "\n",
    "def padded_one_hot_encode(sequence):\n",
    "    mapping = {'A': [1,0,0,0], 'C': [0,1,0,0], 'G': [0,0,1,0], 'T': [0,0,0,1], '0': [0,0,0,0]}\n",
    "    encoding = []\n",
    "    for nucleotide in sequence:\n",
    "         encoding += [mapping[nucleotide]]\n",
    "    return encoding\n",
    "\n",
    "\n",
    "X = df[['UP', 'h35', 'spacs', 'h10', 'disc', 'ITR']]\n",
    "y = df['Normalized Observed']\n",
    "\n",
    "upstream_padding = {}\n",
    "for col in X.columns:\n",
    "    max_len = X[col].apply(len).max()\n",
    "    upstream_padding[col] = np.array([padded_one_hot_encode('0' * (max_len - len(seq)) + seq) for seq in X[col]])\n",
    "\n",
    "X = np.concatenate([upstream_padding[col] for col in X.columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80/20)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores the various input approaches\n",
    "X_dict = {}\n",
    "\n",
    "# stores split training/testing\n",
    "train_test = {}\n",
    "\n",
    "# stores the results\n",
    "results = {}\n",
    "\n",
    "# stores the models\n",
    "models = {}\n",
    "\n",
    "# stores the model history\n",
    "model_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Define CNN model architecture\n",
    "models['CNN'] = Sequential()\n",
    "models['CNN'].add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=X.shape[1:]))\n",
    "models['CNN'].add(MaxPooling1D(pool_size=2))\n",
    "models['CNN'].add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "models['CNN'].add(MaxPooling1D(pool_size=2))\n",
    "models['CNN'].add(Flatten())\n",
    "models['CNN'].add(Dense(64, activation='relu'))\n",
    "models['CNN'].add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "models['CNN'].compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = models['CNN'].fit(X_train,\n",
    "                            y_train,\n",
    "                            epochs=150,\n",
    "                            batch_size=32,\n",
    "                            validation_data=(X_test, y_test),\n",
    "                            callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss = models['CNN'].evaluate(X_test, y_test)\n",
    "\n",
    "results['CNN'] = loss\n",
    "model_history['CNN'] = history\n",
    "models['CNN'].save('CNN.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the test set to visualize the results\n",
    "\n",
    "our_prediction_dict = {}\n",
    "\n",
    "for i in range(len(X)):\n",
    "    our_prediction_dict[i] = models['CNN'].predict(np.array([X[i]]))[0][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions and observed values to a dataframe for visualization\n",
    "\n",
    "our_prediction = pd.DataFrame.from_dict(our_prediction_dict, orient='index', columns=['Value'])\n",
    "observed = df['Normalized Observed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.kdeplot(observed, fill=True, color='blue', label='Observed')\n",
    "sns.kdeplot(our_prediction, fill=True, color='green', label='Our Prediction')\n",
    "\n",
    "plt.title('Kernel Density Plot')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.kdeplot(observed, fill=True, color='blue', label='Observed')\n",
    "sns.kdeplot(our_prediction, fill=True, color='green', label='Our Prediction')\n",
    "\n",
    "plt.title('Kernel Density Plot')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "our_prediction = np.ravel(our_prediction)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(observed, our_prediction, color='blue', alpha=0.5, label='Data points')\n",
    "\n",
    "min_val = min(min(observed), min(our_prediction))\n",
    "max_val = max(max(observed), max(our_prediction))\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='y = x line')\n",
    "\n",
    "plt.title('Observed log(TX/Txref) vs. Our Prediction')\n",
    "plt.xlabel('Observed log(TX/Txref)')\n",
    "plt.ylabel('Our Prediction')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
