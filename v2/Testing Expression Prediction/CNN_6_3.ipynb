{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "### PyTorch k-fold Cross-Validation Hyperparameter Tuning (Bayesian Optimization)\n",
    "\n",
    "This strategy is similar to k-fold cross-validation, but instead of dividing a single dataset into folds, you use each of the 9 datasets sequentially for evaluation while training the model on the remaining 8 datasets. \n",
    "\n",
    "A hyperparameter is a parameter that can be set in order to define any configurable part of a model's learning process. For this CNN, the architecture hyperparameters we optimize are:\n",
    "- The number and structure of Conv1D layers.\n",
    "- Filter sizes, kernel sizes, and strides.\n",
    "- Max-pooling sizes and activation functions for each layer.\n",
    "- The size of the dense layer.\n",
    "- The learning rate for optimization.\n",
    "\n",
    "This approach uses PyTorch to make the sequence generation/infill easier.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "Model chnages: higher TX/expression is now higher prediction.\n",
    "\n",
    "This version optimizes the process of training/testing and uses hyperparameter tuning. It uses a similar architecture to CNN_5_0. It does not include augmented data, just takes the data from La Fleur's supplemental materials including:\n",
    "- La Fleur et al (and De Novo Designs)\n",
    "- Urtecho et al\n",
    "- Hossain et al\n",
    "- Yu et al\n",
    "- Lagator (36N, Pl, and Pr)\n",
    "- Anderson Series\n",
    "\n",
    "We onehot encode each basepair and pad the whole sequence. Because we use a CNN which is designed to identify \"features,\" the input promoter can be any length (with padding) and the model will be able to accurately predict the expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN_6_3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "# Paths and filenames\n",
    "results_file = \"../Testing Expression Prediction/Hyperparameter Search/CNN_6_3_cross_validation/hyperparameter_results.json\"\n",
    "runtime_model_path = \"../Models/CNN_6_3_runtime.pth\"\n",
    "model_path = '../Models/CNN_6_3.pt'\n",
    "\n",
    "# Load all datasets from the directory\n",
    "files = glob.glob('../Data/Cross Validation/*.csv')\n",
    "file_data = {file.split('\\\\')[-1].split('.csv')[0]: load_features(file) for file in files}\n",
    "\n",
    "file_keys = ['Anderson_Series',\n",
    "             'De_Novo_Designs',\n",
    "             'Hossain_et_al',\n",
    "             'Lagator_36N',\n",
    "             'Lagator_Pl',\n",
    "             'Lagator_Pr',\n",
    "             'La_Fleur_et_al',\n",
    "             'Urtecho_et_al',\n",
    "             'Yu_et_al'\n",
    "]\n",
    "\n",
    "# Load previous results (or start fresh)\n",
    "results = load_results(results_file)\n",
    "\n",
    "all_mse_scores = []\n",
    "best_hyperparams = None\n",
    "best_mse = float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a function and breaking up the calls means that if something goes wrong, we dont need to restart (also using saving and loading model states for backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_loocv(i):\n",
    "\n",
    "    test_key = file_keys[i]\n",
    "    X_test, y_test = file_data[test_key]\n",
    "\n",
    "    print(f\"Fold {i + 1}: Test File = {test_key}\")\n",
    "\n",
    "    # Prepare training data for the current fold\n",
    "    X_train_list = [X for key, (X, y) in file_data.items() if key != test_key]\n",
    "    y_train_list = [y for key, (X, y) in file_data.items() if key != test_key]\n",
    "\n",
    "    X_train = np.concatenate(X_train_list, axis=0)\n",
    "    y_train = np.concatenate(y_train_list, axis=0)\n",
    "\n",
    "    # Define input shape for the model\n",
    "    input_shape = (X_train.shape[0], X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "    # Perform hyperparameter search (for this fold)\n",
    "    params = hyperparameter_search(X_train, y_train, input_shape, epochs)\n",
    "    print(f\"Best Hyperparameters for Fold {i + 1}: {params}\")\n",
    "\n",
    "    # Train the model with the best hyperparameters for this fold\n",
    "    model = PyTorchRegressor(input_shape, params, epochs=epochs)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test dataset\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate MSE for this fold\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Fold {i + 1}: MSE = {mse:.4f}\")\n",
    "    all_mse_scores.append(mse)\n",
    "\n",
    "    # Save the hyperparameters, fold metrics, and MSE to results JSON\n",
    "    trial_data = {\n",
    "        \"fold\": i + 1,\n",
    "        \"hyperparameters\": params,\n",
    "        \"mse\": mse,\n",
    "        \"training_data_size\": len(X_train),\n",
    "        \"test_data_size\": len(X_test)\n",
    "    }\n",
    "    results[\"hyperparameter_trials\"].append(trial_data)\n",
    "\n",
    "    # Check if this fold has the best MSE so far\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_hyperparams = params\n",
    "\n",
    "        # Update best model metrics in the results JSON\n",
    "        results[\"best_mse\"] = best_mse\n",
    "        results[\"best_hyperparameters\"] = best_hyperparams\n",
    "\n",
    "        # Save the best model by overriding the previous one\n",
    "        save_best_model(model, runtime_model_path)\n",
    "\n",
    "    # Save the updated results to the JSON file after each fold\n",
    "    save_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_loocv(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_loocv(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_loocv(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_loocv(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_loocv(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_loocv(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_loocv(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_loocv(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_loocv(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(f\"All MSE Scores: {all_mse_scores}\")\n",
    "print(f\"Best Hyperparameters: {best_hyperparams}\")\n",
    "print(f\"Best MSE: {best_mse}\")\n",
    "\n",
    "# Train the final model with the best hyperparameters on all data\n",
    "X_all = np.concatenate([X for X, y in file_data.values()], axis=0)\n",
    "y_all = np.concatenate([y for X, y in file_data.values()], axis=0)\n",
    "\n",
    "input_shape = (X_all.shape[0], X_all.shape[1], X_all.shape[2])\n",
    "\n",
    "final_model = PyTorchRegressor(input_shape, best_hyperparams, epochs=epochs)\n",
    "final_model.fit(X_all, y_all)\n",
    "\n",
    "# Save the final model\n",
    "torch.save(final_model.model.state_dict(), model_path)\n",
    "print(f\"Final model saved to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
