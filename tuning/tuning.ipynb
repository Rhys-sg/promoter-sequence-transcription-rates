{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DNA1 [counts]</th>\n",
       "      <th>DNA2 [counts]</th>\n",
       "      <th>DNA3 [counts]</th>\n",
       "      <th>RNA1 [counts]</th>\n",
       "      <th>RNA2 [counts]</th>\n",
       "      <th>RNA3 [counts]</th>\n",
       "      <th>TX1 [au]</th>\n",
       "      <th>TX2 [au]</th>\n",
       "      <th>TX3 [au]</th>\n",
       "      <th>...</th>\n",
       "      <th>high quality</th>\n",
       "      <th>Observed log(TX/Txref)</th>\n",
       "      <th>Predicted log(TX/Txref)</th>\n",
       "      <th>dG10</th>\n",
       "      <th>dG35</th>\n",
       "      <th>dGDisc</th>\n",
       "      <th>dGITR</th>\n",
       "      <th>dGEXT10</th>\n",
       "      <th>dGSPAC</th>\n",
       "      <th>dGUP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8263</td>\n",
       "      <td>7261</td>\n",
       "      <td>5173</td>\n",
       "      <td>16341</td>\n",
       "      <td>10320</td>\n",
       "      <td>13506</td>\n",
       "      <td>2.258071</td>\n",
       "      <td>1.523795</td>\n",
       "      <td>1.545541</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-3.386326</td>\n",
       "      <td>-3.844827</td>\n",
       "      <td>-1.781524</td>\n",
       "      <td>-1.477218</td>\n",
       "      <td>-0.106428</td>\n",
       "      <td>-0.021112</td>\n",
       "      <td>0.191352</td>\n",
       "      <td>-0.0924</td>\n",
       "      <td>0.400862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5600</td>\n",
       "      <td>4886</td>\n",
       "      <td>3264</td>\n",
       "      <td>10986</td>\n",
       "      <td>7250</td>\n",
       "      <td>10800</td>\n",
       "      <td>2.240001</td>\n",
       "      <td>1.590845</td>\n",
       "      <td>1.958709</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-3.503140</td>\n",
       "      <td>-3.905283</td>\n",
       "      <td>-1.781524</td>\n",
       "      <td>-1.477218</td>\n",
       "      <td>-0.166884</td>\n",
       "      <td>-0.021112</td>\n",
       "      <td>0.191352</td>\n",
       "      <td>-0.0924</td>\n",
       "      <td>0.400862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7898</td>\n",
       "      <td>6790</td>\n",
       "      <td>4752</td>\n",
       "      <td>19572</td>\n",
       "      <td>32204</td>\n",
       "      <td>30585</td>\n",
       "      <td>2.829533</td>\n",
       "      <td>5.084911</td>\n",
       "      <td>3.810029</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-4.207206</td>\n",
       "      <td>-3.905283</td>\n",
       "      <td>-1.781524</td>\n",
       "      <td>-1.477218</td>\n",
       "      <td>-0.166884</td>\n",
       "      <td>-0.021112</td>\n",
       "      <td>0.191352</td>\n",
       "      <td>-0.0924</td>\n",
       "      <td>0.400862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10651</td>\n",
       "      <td>9875</td>\n",
       "      <td>6466</td>\n",
       "      <td>15734</td>\n",
       "      <td>16246</td>\n",
       "      <td>18908</td>\n",
       "      <td>1.686729</td>\n",
       "      <td>1.763814</td>\n",
       "      <td>1.731036</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-3.392439</td>\n",
       "      <td>-3.877808</td>\n",
       "      <td>-1.781524</td>\n",
       "      <td>-1.477218</td>\n",
       "      <td>-0.139409</td>\n",
       "      <td>-0.021112</td>\n",
       "      <td>0.191352</td>\n",
       "      <td>-0.0924</td>\n",
       "      <td>0.400862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12188</td>\n",
       "      <td>10793</td>\n",
       "      <td>6965</td>\n",
       "      <td>28609</td>\n",
       "      <td>21796</td>\n",
       "      <td>26803</td>\n",
       "      <td>2.680198</td>\n",
       "      <td>2.165100</td>\n",
       "      <td>2.278025</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-3.698903</td>\n",
       "      <td>-3.672384</td>\n",
       "      <td>-1.781524</td>\n",
       "      <td>-1.477218</td>\n",
       "      <td>0.066015</td>\n",
       "      <td>-0.021112</td>\n",
       "      <td>0.191352</td>\n",
       "      <td>-0.0924</td>\n",
       "      <td>0.400862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  DNA1 [counts]  DNA2 [counts]  DNA3 [counts]  RNA1 [counts]  \\\n",
       "0   0           8263           7261           5173          16341   \n",
       "1   1           5600           4886           3264          10986   \n",
       "2   2           7898           6790           4752          19572   \n",
       "3   3          10651           9875           6466          15734   \n",
       "4   4          12188          10793           6965          28609   \n",
       "\n",
       "   RNA2 [counts]  RNA3 [counts]  TX1 [au]  TX2 [au]  TX3 [au]  ...  \\\n",
       "0          10320          13506  2.258071  1.523795  1.545541  ...   \n",
       "1           7250          10800  2.240001  1.590845  1.958709  ...   \n",
       "2          32204          30585  2.829533  5.084911  3.810029  ...   \n",
       "3          16246          18908  1.686729  1.763814  1.731036  ...   \n",
       "4          21796          26803  2.680198  2.165100  2.278025  ...   \n",
       "\n",
       "   high quality  Observed log(TX/Txref) Predicted log(TX/Txref)      dG10  \\\n",
       "0           Yes               -3.386326               -3.844827 -1.781524   \n",
       "1           Yes               -3.503140               -3.905283 -1.781524   \n",
       "2           Yes               -4.207206               -3.905283 -1.781524   \n",
       "3           Yes               -3.392439               -3.877808 -1.781524   \n",
       "4           Yes               -3.698903               -3.672384 -1.781524   \n",
       "\n",
       "       dG35    dGDisc     dGITR   dGEXT10  dGSPAC      dGUP  \n",
       "0 -1.477218 -0.106428 -0.021112  0.191352 -0.0924  0.400862  \n",
       "1 -1.477218 -0.166884 -0.021112  0.191352 -0.0924  0.400862  \n",
       "2 -1.477218 -0.166884 -0.021112  0.191352 -0.0924  0.400862  \n",
       "3 -1.477218 -0.139409 -0.021112  0.191352 -0.0924  0.400862  \n",
       "4 -1.477218  0.066015 -0.021112  0.191352 -0.0924  0.400862  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset into a pandas data frame\n",
    "\n",
    "df = pd.read_csv('../41467_2022_32829_MOESM5_ESM.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UP</th>\n",
       "      <th>h35</th>\n",
       "      <th>spacs</th>\n",
       "      <th>h10</th>\n",
       "      <th>disc</th>\n",
       "      <th>ITR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTTTCTATCTACGTAC</td>\n",
       "      <td>TTGACA</td>\n",
       "      <td>CTATTTCCTATTTCTCT</td>\n",
       "      <td>TATAAT</td>\n",
       "      <td>CCCCGCGG</td>\n",
       "      <td>CTCTACCTTAGTTTGTACGTT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TTTTCTATCTACGTAC</td>\n",
       "      <td>TTGACA</td>\n",
       "      <td>CTATTTCCTATTTCTCT</td>\n",
       "      <td>TATAAT</td>\n",
       "      <td>CGCGGCGG</td>\n",
       "      <td>CTCTACCTTAGTTTGTACGTT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TTTTCTATCTACGTAC</td>\n",
       "      <td>TTGACA</td>\n",
       "      <td>CTATTTCCTATTTCTCT</td>\n",
       "      <td>TATAAT</td>\n",
       "      <td>CGCGCCCG</td>\n",
       "      <td>CTCTACCTTAGTTTGTACGTT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TTTTCTATCTACGTAC</td>\n",
       "      <td>TTGACA</td>\n",
       "      <td>CTATTTCCTATTTCTCT</td>\n",
       "      <td>TATAAT</td>\n",
       "      <td>GCGGCGGC</td>\n",
       "      <td>CTCTACCTTAGTTTGTACGTT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TTTTCTATCTACGTAC</td>\n",
       "      <td>TTGACA</td>\n",
       "      <td>CTATTTCCTATTTCTCT</td>\n",
       "      <td>TATAAT</td>\n",
       "      <td>CGGGGGGC</td>\n",
       "      <td>CTCTACCTTAGTTTGTACGTT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 UP     h35              spacs     h10      disc  \\\n",
       "0  TTTTCTATCTACGTAC  TTGACA  CTATTTCCTATTTCTCT  TATAAT  CCCCGCGG   \n",
       "1  TTTTCTATCTACGTAC  TTGACA  CTATTTCCTATTTCTCT  TATAAT  CGCGGCGG   \n",
       "2  TTTTCTATCTACGTAC  TTGACA  CTATTTCCTATTTCTCT  TATAAT  CGCGCCCG   \n",
       "3  TTTTCTATCTACGTAC  TTGACA  CTATTTCCTATTTCTCT  TATAAT  GCGGCGGC   \n",
       "4  TTTTCTATCTACGTAC  TTGACA  CTATTTCCTATTTCTCT  TATAAT  CGGGGGGC   \n",
       "\n",
       "                     ITR  \n",
       "0  CTCTACCTTAGTTTGTACGTT  \n",
       "1  CTCTACCTTAGTTTGTACGTT  \n",
       "2  CTCTACCTTAGTTTGTACGTT  \n",
       "3  CTCTACCTTAGTTTGTACGTT  \n",
       "4  CTCTACCTTAGTTTGTACGTT  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All input and output data\n",
    "\n",
    "X = df[['UP', 'h35', 'spacs', 'h10', 'disc', 'ITR']]\n",
    "y = df['Observed log(TX/Txref)']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 140 rows\n"
     ]
    }
   ],
   "source": [
    "# remove all rows with spacer sequences that are not 16-18 nucleotides long\n",
    "\n",
    "\n",
    "_df = df[(df['spacs'].str.len() >= 15) & (df['spacs'].str.len() <= 19)]\n",
    "\n",
    "\n",
    "X = _df[['UP', 'h35', 'spacs', 'h10', 'disc', 'ITR']]\n",
    "y = _df['Observed log(TX/Txref)']\n",
    "\n",
    "print(f'Removed {df.shape[0] - _df.shape[0]} rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to one-hot encode DNA sequences, including padding 0's\n",
    "\n",
    "def padded_one_hot_encode(sequence):\n",
    "    mapping = {'A': [1,0,0,0], 'C': [0,1,0,0], 'G': [0,0,1,0], 'T': [0,0,0,1], '0': [0,0,0,0]}\n",
    "    encoding = []\n",
    "    for nucleotide in sequence:\n",
    "         encoding += [mapping[nucleotide]]\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_padding = {}\n",
    "\n",
    "for col in X.columns:\n",
    "    max_len = X[col].apply(len).max()\n",
    "    upstream_padding[col] = np.array([padded_one_hot_encode('0' * (max_len - len(seq)) + seq) for seq in X[col]])\n",
    "\n",
    "# Concatenate the one-hot encoded, upstream-padded sequences\n",
    "X = np.concatenate([upstream_padding[col] for col in X.columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data in training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Input\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initModel(hidden_layers, neurons, epochs=150, batch_size=32):\n",
    "    # Define RNN model architecture\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Input(shape=X.shape[1:])) # dynamically generated input shape based on X data\n",
    "    for i in range(hidden_layers-1):\n",
    "        regressor.add(LSTM(neurons, return_sequences=True))\n",
    "    regressor.add(LSTM(neurons))\n",
    "    regressor.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    regressor.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Early stopping to prevent overfitting\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = regressor.fit(X_train,\n",
    "                            y_train,\n",
    "                            epochs=epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            validation_data=(X_test, y_test),\n",
    "                            callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the model\n",
    "    return regressor, regressor.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layers: 1, Neurons 16\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 1.7647 - val_loss: 0.5081\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.4672 - val_loss: 0.3525\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.3468 - val_loss: 0.3264\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.3219 - val_loss: 0.3210\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2931 - val_loss: 0.2794\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.2828 - val_loss: 0.2693\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 0.2656 - val_loss: 0.2713\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - loss: 0.2632 - val_loss: 0.2557\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2485 - val_loss: 0.2547\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2475 - val_loss: 0.2658\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2575 - val_loss: 0.2500\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2504 - val_loss: 0.2481\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2523 - val_loss: 0.2421\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2456 - val_loss: 0.2421\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2367 - val_loss: 0.2440\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2436 - val_loss: 0.2398\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2371 - val_loss: 0.2483\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2459 - val_loss: 0.2453\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2346 - val_loss: 0.2372\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2421 - val_loss: 0.2406\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2321 - val_loss: 0.2349\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2334 - val_loss: 0.2501\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2382 - val_loss: 0.2543\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2340 - val_loss: 0.2301\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2311 - val_loss: 0.2255\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2227 - val_loss: 0.2305\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2243 - val_loss: 0.2313\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2157 - val_loss: 0.2239\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2297 - val_loss: 0.2242\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2151 - val_loss: 0.2261\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2187 - val_loss: 0.2268\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2235 - val_loss: 0.2160\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2129 - val_loss: 0.2249\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2229 - val_loss: 0.2240\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2199 - val_loss: 0.2153\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.2041 - val_loss: 0.2230\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2079 - val_loss: 0.2164\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2152 - val_loss: 0.2211\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2075 - val_loss: 0.2124\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2017 - val_loss: 0.2258\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2181 - val_loss: 0.2186\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2117 - val_loss: 0.2240\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2200 - val_loss: 0.2054\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2032 - val_loss: 0.2094\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1961 - val_loss: 0.2070\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2116 - val_loss: 0.2080\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2098 - val_loss: 0.2037\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2031 - val_loss: 0.2050\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1972 - val_loss: 0.2024\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1973 - val_loss: 0.2062\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1961 - val_loss: 0.2053\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1976 - val_loss: 0.2054\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2018 - val_loss: 0.1996\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1974 - val_loss: 0.2015\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2035 - val_loss: 0.2056\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2025 - val_loss: 0.2079\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1986 - val_loss: 0.2038\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1952 - val_loss: 0.2039\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.2009 - val_loss: 0.2022\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1956 - val_loss: 0.1987\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1869 - val_loss: 0.2003\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1921 - val_loss: 0.2006\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1914 - val_loss: 0.1936\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1936 - val_loss: 0.2038\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1981 - val_loss: 0.1956\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1932 - val_loss: 0.2002\n",
      "Epoch 67/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1972 - val_loss: 0.1942\n",
      "Epoch 68/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1967 - val_loss: 0.1962\n",
      "Epoch 69/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1854 - val_loss: 0.2018\n",
      "Epoch 70/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1848 - val_loss: 0.2119\n",
      "Epoch 71/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.2067 - val_loss: 0.1967\n",
      "Epoch 72/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1955 - val_loss: 0.1933\n",
      "Epoch 73/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1958 - val_loss: 0.1928\n",
      "Epoch 74/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1816 - val_loss: 0.1915\n",
      "Epoch 75/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1945 - val_loss: 0.1917\n",
      "Epoch 76/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1927 - val_loss: 0.1935\n",
      "Epoch 77/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1793 - val_loss: 0.1912\n",
      "Epoch 78/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1891 - val_loss: 0.1930\n",
      "Epoch 79/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1853 - val_loss: 0.1907\n",
      "Epoch 80/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1858 - val_loss: 0.1892\n",
      "Epoch 81/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1878 - val_loss: 0.2000\n",
      "Epoch 82/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1961 - val_loss: 0.1885\n",
      "Epoch 83/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1873 - val_loss: 0.1943\n",
      "Epoch 84/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1844 - val_loss: 0.1891\n",
      "Epoch 85/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1932 - val_loss: 0.1980\n",
      "Epoch 86/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1878 - val_loss: 0.1915\n",
      "Epoch 87/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1813 - val_loss: 0.1896\n",
      "Epoch 88/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1862 - val_loss: 0.1921\n",
      "Epoch 89/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1876 - val_loss: 0.1902\n",
      "Epoch 90/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1895 - val_loss: 0.1867\n",
      "Epoch 91/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1886 - val_loss: 0.1880\n",
      "Epoch 92/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1790 - val_loss: 0.1908\n",
      "Epoch 93/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1764 - val_loss: 0.1907\n",
      "Epoch 94/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1872 - val_loss: 0.1842\n",
      "Epoch 95/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1861 - val_loss: 0.1885\n",
      "Epoch 96/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1748 - val_loss: 0.1862\n",
      "Epoch 97/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1800 - val_loss: 0.1863\n",
      "Epoch 98/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1791 - val_loss: 0.1837\n",
      "Epoch 99/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1822 - val_loss: 0.1891\n",
      "Epoch 100/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1772 - val_loss: 0.1899\n",
      "Epoch 101/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1777 - val_loss: 0.1855\n",
      "Epoch 102/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1826 - val_loss: 0.1853\n",
      "Epoch 103/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1788 - val_loss: 0.1883\n",
      "Epoch 104/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1873 - val_loss: 0.1836\n",
      "Epoch 105/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1791 - val_loss: 0.1844\n",
      "Epoch 106/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1754 - val_loss: 0.1809\n",
      "Epoch 107/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1794 - val_loss: 0.1842\n",
      "Epoch 108/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1748 - val_loss: 0.1844\n",
      "Epoch 109/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1823 - val_loss: 0.1801\n",
      "Epoch 110/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1721 - val_loss: 0.1831\n",
      "Epoch 111/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1724 - val_loss: 0.1849\n",
      "Epoch 112/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1730 - val_loss: 0.1827\n",
      "Epoch 113/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1766 - val_loss: 0.1819\n",
      "Epoch 114/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1768 - val_loss: 0.1801\n",
      "Epoch 115/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1721 - val_loss: 0.1815\n",
      "Epoch 116/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1722 - val_loss: 0.1773\n",
      "Epoch 117/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1783 - val_loss: 0.1773\n",
      "Epoch 118/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1816 - val_loss: 0.1795\n",
      "Epoch 119/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1709 - val_loss: 0.1800\n",
      "Epoch 120/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1827 - val_loss: 0.1879\n",
      "Epoch 121/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1738 - val_loss: 0.1815\n",
      "Epoch 122/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1681 - val_loss: 0.1786\n",
      "Epoch 123/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1797 - val_loss: 0.1797\n",
      "Epoch 124/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1743 - val_loss: 0.1777\n",
      "Epoch 125/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1756 - val_loss: 0.1800\n",
      "Epoch 126/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1656 - val_loss: 0.1749\n",
      "Epoch 127/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1692 - val_loss: 0.1753\n",
      "Epoch 128/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1737 - val_loss: 0.1759\n",
      "Epoch 129/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1636 - val_loss: 0.1757\n",
      "Epoch 130/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1694 - val_loss: 0.1738\n",
      "Epoch 131/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1690 - val_loss: 0.1736\n",
      "Epoch 132/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1660 - val_loss: 0.1759\n",
      "Epoch 133/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1694 - val_loss: 0.1739\n",
      "Epoch 134/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1667 - val_loss: 0.1791\n",
      "Epoch 135/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1732 - val_loss: 0.1792\n",
      "Epoch 136/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1697 - val_loss: 0.1746\n",
      "Epoch 137/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1630 - val_loss: 0.1767\n",
      "Epoch 138/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1654 - val_loss: 0.1736\n",
      "Epoch 139/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1659 - val_loss: 0.1751\n",
      "Epoch 140/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1623 - val_loss: 0.1785\n",
      "Epoch 141/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1683 - val_loss: 0.1769\n",
      "Epoch 142/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1651 - val_loss: 0.1736\n",
      "Epoch 143/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.1758 - val_loss: 0.1786\n",
      "Epoch 144/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1731 - val_loss: 0.1717\n",
      "Epoch 145/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1614 - val_loss: 0.1702\n",
      "Epoch 146/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1611 - val_loss: 0.1715\n",
      "Epoch 147/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1603 - val_loss: 0.1698\n",
      "Epoch 148/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1621 - val_loss: 0.1695\n",
      "Epoch 149/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1608 - val_loss: 0.1710\n",
      "Epoch 150/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1699 - val_loss: 0.1685\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1706\n",
      "Hidden Layers: 1, Neurons 32\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 1.6679 - val_loss: 0.4212\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.3620 - val_loss: 0.3112\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.3009 - val_loss: 0.3048\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2809 - val_loss: 0.2947\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2631 - val_loss: 0.2647\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2509 - val_loss: 0.2316\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2326 - val_loss: 0.2399\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2356 - val_loss: 0.2683\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2266 - val_loss: 0.2348\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2562 - val_loss: 0.2143\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2203 - val_loss: 0.2164\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2241 - val_loss: 0.2279\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2231 - val_loss: 0.2355\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2253 - val_loss: 0.2200\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2167 - val_loss: 0.2215\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2148 - val_loss: 0.2111\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2091 - val_loss: 0.2220\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2043 - val_loss: 0.2101\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2068 - val_loss: 0.2066\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2164 - val_loss: 0.2057\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2151 - val_loss: 0.2075\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2081 - val_loss: 0.1971\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2014 - val_loss: 0.2056\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2094 - val_loss: 0.2138\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2030 - val_loss: 0.2049\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1995 - val_loss: 0.2095\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2029 - val_loss: 0.1891\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1979 - val_loss: 0.1971\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2126 - val_loss: 0.1933\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1951 - val_loss: 0.1974\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1931 - val_loss: 0.1894\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1917 - val_loss: 0.1846\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1882 - val_loss: 0.1863\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1926 - val_loss: 0.2038\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1831 - val_loss: 0.1890\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1822 - val_loss: 0.1882\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1885 - val_loss: 0.1905\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1918 - val_loss: 0.1817\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1910 - val_loss: 0.1834\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1848 - val_loss: 0.1816\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1901 - val_loss: 0.1814\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1846 - val_loss: 0.1807\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1884 - val_loss: 0.1819\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1834 - val_loss: 0.1816\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1819 - val_loss: 0.1832\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1860 - val_loss: 0.1800\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1808 - val_loss: 0.1806\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1751 - val_loss: 0.1823\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1748 - val_loss: 0.1742\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1723 - val_loss: 0.1809\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1723 - val_loss: 0.1693\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1728 - val_loss: 0.1701\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1772 - val_loss: 0.1735\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1711 - val_loss: 0.1764\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1724 - val_loss: 0.1721\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1668 - val_loss: 0.1663\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1611 - val_loss: 0.1693\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1617 - val_loss: 0.1651\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1658 - val_loss: 0.1670\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1625 - val_loss: 0.1687\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1639 - val_loss: 0.1667\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1643 - val_loss: 0.1652\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1637 - val_loss: 0.1675\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1615 - val_loss: 0.1718\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1587 - val_loss: 0.1703\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1585 - val_loss: 0.1675\n",
      "Epoch 67/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1620 - val_loss: 0.1660\n",
      "Epoch 68/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1585 - val_loss: 0.1628\n",
      "Epoch 69/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1551 - val_loss: 0.1625\n",
      "Epoch 70/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1540 - val_loss: 0.1692\n",
      "Epoch 71/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1543 - val_loss: 0.1588\n",
      "Epoch 72/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1624 - val_loss: 0.1607\n",
      "Epoch 73/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1567 - val_loss: 0.1584\n",
      "Epoch 74/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1508 - val_loss: 0.1610\n",
      "Epoch 75/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1607 - val_loss: 0.1675\n",
      "Epoch 76/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1639 - val_loss: 0.1585\n",
      "Epoch 77/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1579 - val_loss: 0.1615\n",
      "Epoch 78/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1557 - val_loss: 0.1612\n",
      "Epoch 79/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1548 - val_loss: 0.1591\n",
      "Epoch 80/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1600 - val_loss: 0.1579\n",
      "Epoch 81/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1528 - val_loss: 0.1579\n",
      "Epoch 82/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1535 - val_loss: 0.1568\n",
      "Epoch 83/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1573 - val_loss: 0.1542\n",
      "Epoch 84/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1508 - val_loss: 0.1559\n",
      "Epoch 85/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1469 - val_loss: 0.1565\n",
      "Epoch 86/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1527 - val_loss: 0.1553\n",
      "Epoch 87/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1513 - val_loss: 0.1575\n",
      "Epoch 88/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1539 - val_loss: 0.1569\n",
      "Epoch 89/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1475 - val_loss: 0.1526\n",
      "Epoch 90/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1500 - val_loss: 0.1559\n",
      "Epoch 91/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1539 - val_loss: 0.1543\n",
      "Epoch 92/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1448 - val_loss: 0.1601\n",
      "Epoch 93/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1588 - val_loss: 0.1573\n",
      "Epoch 94/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1494 - val_loss: 0.1552\n",
      "Epoch 95/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1413 - val_loss: 0.1555\n",
      "Epoch 96/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1502 - val_loss: 0.1534\n",
      "Epoch 97/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1483 - val_loss: 0.1529\n",
      "Epoch 98/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1441 - val_loss: 0.1538\n",
      "Epoch 99/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1483 - val_loss: 0.1499\n",
      "Epoch 100/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1475 - val_loss: 0.1582\n",
      "Epoch 101/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1438 - val_loss: 0.1520\n",
      "Epoch 102/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1455 - val_loss: 0.1522\n",
      "Epoch 103/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1410 - val_loss: 0.1657\n",
      "Epoch 104/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1472 - val_loss: 0.1528\n",
      "Epoch 105/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1397 - val_loss: 0.1514\n",
      "Epoch 106/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1425 - val_loss: 0.1547\n",
      "Epoch 107/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1434 - val_loss: 0.1522\n",
      "Epoch 108/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1436 - val_loss: 0.1497\n",
      "Epoch 109/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1407 - val_loss: 0.1521\n",
      "Epoch 110/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1430 - val_loss: 0.1555\n",
      "Epoch 111/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.1442 - val_loss: 0.1557\n",
      "Epoch 112/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1485 - val_loss: 0.1519\n",
      "Epoch 113/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1445 - val_loss: 0.1530\n",
      "Epoch 114/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1427 - val_loss: 0.1529\n",
      "Epoch 115/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1451 - val_loss: 0.1505\n",
      "Epoch 116/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1450 - val_loss: 0.1501\n",
      "Epoch 117/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1446 - val_loss: 0.1523\n",
      "Epoch 118/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1423 - val_loss: 0.1490\n",
      "Epoch 119/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1388 - val_loss: 0.1514\n",
      "Epoch 120/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1409 - val_loss: 0.1471\n",
      "Epoch 121/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1380 - val_loss: 0.1533\n",
      "Epoch 122/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1419 - val_loss: 0.1486\n",
      "Epoch 123/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1447 - val_loss: 0.1518\n",
      "Epoch 124/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1482 - val_loss: 0.1500\n",
      "Epoch 125/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1361 - val_loss: 0.1479\n",
      "Epoch 126/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1413 - val_loss: 0.1508\n",
      "Epoch 127/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1390 - val_loss: 0.1479\n",
      "Epoch 128/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1406 - val_loss: 0.1484\n",
      "Epoch 129/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1339 - val_loss: 0.1531\n",
      "Epoch 130/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.1407 - val_loss: 0.1481\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1526\n",
      "Hidden Layers: 1, Neurons 64\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 1.2693 - val_loss: 0.5426\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.5050 - val_loss: 0.3868\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.3652 - val_loss: 0.3584\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2988 - val_loss: 0.3238\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2526 - val_loss: 0.2608\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2517 - val_loss: 0.2333\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2392 - val_loss: 0.2269\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2274 - val_loss: 0.2410\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2189 - val_loss: 0.2227\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2117 - val_loss: 0.2206\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2226 - val_loss: 0.2271\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2166 - val_loss: 0.2402\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2121 - val_loss: 0.2470\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2206 - val_loss: 0.2123\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2173 - val_loss: 0.2088\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2117 - val_loss: 0.2127\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2373 - val_loss: 0.4653\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.3430 - val_loss: 0.2311\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2272 - val_loss: 0.2101\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2177 - val_loss: 0.2117\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2157 - val_loss: 0.2289\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2180 - val_loss: 0.2112\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2076 - val_loss: 0.2053\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.2073 - val_loss: 0.2089\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2086 - val_loss: 0.2096\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2180 - val_loss: 0.2157\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2082 - val_loss: 0.2015\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2058 - val_loss: 0.2039\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1947 - val_loss: 0.2050\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.2022 - val_loss: 0.2052\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1940 - val_loss: 0.1983\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1990 - val_loss: 0.1942\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1880 - val_loss: 0.1929\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1951 - val_loss: 0.1928\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1893 - val_loss: 0.1887\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1880 - val_loss: 0.2121\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1921 - val_loss: 0.1857\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1842 - val_loss: 0.1898\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1754 - val_loss: 0.1929\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1852 - val_loss: 0.1839\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1767 - val_loss: 0.1755\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1697 - val_loss: 0.1861\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1791 - val_loss: 0.1736\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1718 - val_loss: 0.1743\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1734 - val_loss: 0.1719\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1812 - val_loss: 0.1708\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1737 - val_loss: 0.1676\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1726 - val_loss: 0.1715\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1681 - val_loss: 0.1662\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1637 - val_loss: 0.1657\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1624 - val_loss: 0.1666\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1711 - val_loss: 0.1647\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.1605 - val_loss: 0.1648\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1566 - val_loss: 0.1634\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1591 - val_loss: 0.1769\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1634 - val_loss: 0.1708\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1638 - val_loss: 0.1608\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.1627 - val_loss: 0.1611\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1629 - val_loss: 0.1634\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1570 - val_loss: 0.1615\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1524 - val_loss: 0.1720\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1596 - val_loss: 0.1591\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1504 - val_loss: 0.1613\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1524 - val_loss: 0.1611\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1511 - val_loss: 0.1595\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1500 - val_loss: 0.1539\n",
      "Epoch 67/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1485 - val_loss: 0.1553\n",
      "Epoch 68/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1464 - val_loss: 0.1568\n",
      "Epoch 69/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1449 - val_loss: 0.1544\n",
      "Epoch 70/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1445 - val_loss: 0.1582\n",
      "Epoch 71/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1454 - val_loss: 0.1511\n",
      "Epoch 72/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 0.1423 - val_loss: 0.1508\n",
      "Epoch 73/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1401 - val_loss: 0.1492\n",
      "Epoch 74/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1443 - val_loss: 0.1525\n",
      "Epoch 75/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1400 - val_loss: 0.1518\n",
      "Epoch 76/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1418 - val_loss: 0.1531\n",
      "Epoch 77/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1356 - val_loss: 0.1468\n",
      "Epoch 78/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1398 - val_loss: 0.1491\n",
      "Epoch 79/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1404 - val_loss: 0.1498\n",
      "Epoch 80/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1371 - val_loss: 0.1497\n",
      "Epoch 81/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1394 - val_loss: 0.1468\n",
      "Epoch 82/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1386 - val_loss: 0.1520\n",
      "Epoch 83/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1317 - val_loss: 0.1494\n",
      "Epoch 84/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1277 - val_loss: 0.1491\n",
      "Epoch 85/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1449 - val_loss: 0.1470\n",
      "Epoch 86/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1352 - val_loss: 0.1469\n",
      "Epoch 87/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1364 - val_loss: 0.1537\n",
      "Epoch 88/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1369 - val_loss: 0.1497\n",
      "Epoch 89/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1285 - val_loss: 0.1517\n",
      "Epoch 90/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1364 - val_loss: 0.1462\n",
      "Epoch 91/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1417 - val_loss: 0.1508\n",
      "Epoch 92/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1310 - val_loss: 0.1494\n",
      "Epoch 93/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1345 - val_loss: 0.1506\n",
      "Epoch 94/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1293 - val_loss: 0.1450\n",
      "Epoch 95/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1347 - val_loss: 0.1492\n",
      "Epoch 96/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1346 - val_loss: 0.1455\n",
      "Epoch 97/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1280 - val_loss: 0.1469\n",
      "Epoch 98/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1243 - val_loss: 0.1456\n",
      "Epoch 99/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1317 - val_loss: 0.1509\n",
      "Epoch 100/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1281 - val_loss: 0.1461\n",
      "Epoch 101/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1333 - val_loss: 0.1509\n",
      "Epoch 102/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.1303 - val_loss: 0.1474\n",
      "Epoch 103/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1260 - val_loss: 0.1490\n",
      "Epoch 104/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.1305 - val_loss: 0.1520\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1544\n",
      "Hidden Layers: 1, Neurons 96\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 1.2281 - val_loss: 0.5107\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.5072 - val_loss: 0.4534\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.4439 - val_loss: 0.4516\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.4496 - val_loss: 0.4495\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.4401 - val_loss: 0.4485\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.4335 - val_loss: 0.4473\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.4462 - val_loss: 0.4492\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.4464 - val_loss: 0.4256\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.4369 - val_loss: 0.4470\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.4357 - val_loss: 0.4307\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.3561 - val_loss: 0.2811\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2673 - val_loss: 0.2580\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2392 - val_loss: 0.2298\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2392 - val_loss: 0.2453\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2225 - val_loss: 0.2394\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2240 - val_loss: 0.2497\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2138 - val_loss: 0.2108\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2106 - val_loss: 0.2077\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2198 - val_loss: 0.2174\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2065 - val_loss: 0.2062\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.2089 - val_loss: 0.1999\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2013 - val_loss: 0.1983\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1972 - val_loss: 0.2039\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1988 - val_loss: 0.2073\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1992 - val_loss: 0.1976\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1990 - val_loss: 0.1965\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1920 - val_loss: 0.1880\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1878 - val_loss: 0.1817\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1814 - val_loss: 0.1788\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1755 - val_loss: 0.1765\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1799 - val_loss: 0.1665\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1700 - val_loss: 0.1774\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1757 - val_loss: 0.1666\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1703 - val_loss: 0.1597\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1585 - val_loss: 0.1572\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1597 - val_loss: 0.1595\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1654 - val_loss: 0.1689\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1586 - val_loss: 0.1547\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1551 - val_loss: 0.1499\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1470 - val_loss: 0.1569\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1462 - val_loss: 0.1524\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1533 - val_loss: 0.1476\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1482 - val_loss: 0.1479\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1460 - val_loss: 0.1490\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1341 - val_loss: 0.1564\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1420 - val_loss: 0.1483\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1406 - val_loss: 0.1541\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1437 - val_loss: 0.1460\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1473 - val_loss: 0.1447\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1377 - val_loss: 0.1487\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1447 - val_loss: 0.1495\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1400 - val_loss: 0.1524\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1378 - val_loss: 0.1446\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1355 - val_loss: 0.1482\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1390 - val_loss: 0.1562\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1390 - val_loss: 0.1461\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1376 - val_loss: 0.1418\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1276 - val_loss: 0.1477\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1351 - val_loss: 0.1469\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1318 - val_loss: 0.1442\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1363 - val_loss: 0.1488\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1373 - val_loss: 0.1459\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1339 - val_loss: 0.1483\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1325 - val_loss: 0.1456\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1312 - val_loss: 0.1488\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1293 - val_loss: 0.1453\n",
      "Epoch 67/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.1250 - val_loss: 0.1471\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1480\n",
      "Hidden Layers: 1, Neurons 128\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - loss: 1.1840 - val_loss: 0.4786\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.5003 - val_loss: 0.4604\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.4523 - val_loss: 0.4852\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.3665 - val_loss: 0.2870\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2612 - val_loss: 0.2492\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.2582 - val_loss: 0.2830\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2337 - val_loss: 0.2229\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2388 - val_loss: 0.2592\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2282 - val_loss: 0.2232\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2147 - val_loss: 0.2141\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2422 - val_loss: 0.2221\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2333 - val_loss: 0.2244\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2150 - val_loss: 0.2143\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2162 - val_loss: 0.2226\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2203 - val_loss: 0.2216\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.2126 - val_loss: 0.2108\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2126 - val_loss: 0.2121\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2123 - val_loss: 0.2371\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2028 - val_loss: 0.2106\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2079 - val_loss: 0.1963\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1905 - val_loss: 0.2115\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2091 - val_loss: 0.2054\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1944 - val_loss: 0.1931\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.1909 - val_loss: 0.1853\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1848 - val_loss: 0.1816\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1818 - val_loss: 0.1870\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1805 - val_loss: 0.1775\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1764 - val_loss: 0.1965\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1872 - val_loss: 0.1898\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1761 - val_loss: 0.1682\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1639 - val_loss: 0.1555\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1584 - val_loss: 0.1597\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1593 - val_loss: 0.1568\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.1575 - val_loss: 0.1676\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1454 - val_loss: 0.1557\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1446 - val_loss: 0.1520\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.1447 - val_loss: 0.1514\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1498 - val_loss: 0.1503\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1506 - val_loss: 0.1493\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1442 - val_loss: 0.1516\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1429 - val_loss: 0.1445\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1400 - val_loss: 0.1456\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1419 - val_loss: 0.1502\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1425 - val_loss: 0.1489\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1399 - val_loss: 0.1461\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1437 - val_loss: 0.1506\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1401 - val_loss: 0.1543\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1393 - val_loss: 0.1446\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1327 - val_loss: 0.1486\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1308 - val_loss: 0.1461\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1349 - val_loss: 0.1509\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1509\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = 1\n",
    "neurons = [16, 32, 64, 96, 128]\n",
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "for n in neurons:\n",
    "    print(f\"Hidden Layers: {hidden_layers}, Neurons {n}\"), \n",
    "    regressor, mse = initModel(hidden_layers, n, epochs, batch_size)\n",
    "    results.append({'MSE': mse, 'Hidden Layers': hidden_layers, 'Neurons': n, 'Model': regressor})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Neurons</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141757</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;Sequential name=sequential_3, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144534</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;Sequential name=sequential_4, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.145036</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_2, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.147063</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_1, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.168463</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential, built=True&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSE  Hidden Layers  Neurons  \\\n",
       "3  0.141757              1       96   \n",
       "4  0.144534              1      128   \n",
       "2  0.145036              1       64   \n",
       "1  0.147063              1       32   \n",
       "0  0.168463              1       16   \n",
       "\n",
       "                                        Model  \n",
       "3  <Sequential name=sequential_3, built=True>  \n",
       "4  <Sequential name=sequential_4, built=True>  \n",
       "2  <Sequential name=sequential_2, built=True>  \n",
       "1  <Sequential name=sequential_1, built=True>  \n",
       "0    <Sequential name=sequential, built=True>  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "df_results.sort_values(by='MSE').head(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layers: 2, Neurons 16\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - loss: 2.1447 - val_loss: 0.5425\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.5518 - val_loss: 0.5234\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.4095 - val_loss: 0.2965\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2916 - val_loss: 0.2770\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2786 - val_loss: 0.2720\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2774 - val_loss: 0.2787\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2607 - val_loss: 0.2862\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2563 - val_loss: 0.2462\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2427 - val_loss: 0.2291\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2464 - val_loss: 0.2317\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.2350 - val_loss: 0.2299\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.2343 - val_loss: 0.2380\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.2368 - val_loss: 0.2272\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2237 - val_loss: 0.2403\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2258 - val_loss: 0.2249\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.2346 - val_loss: 0.2423\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.2231 - val_loss: 0.2356\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2289 - val_loss: 0.2383\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.2221 - val_loss: 0.2209\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2221 - val_loss: 0.2260\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2235 - val_loss: 0.2216\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2218 - val_loss: 0.2255\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2199 - val_loss: 0.2387\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2180 - val_loss: 0.2198\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2069 - val_loss: 0.2346\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2150 - val_loss: 0.2119\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2163 - val_loss: 0.2178\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2312 - val_loss: 0.2097\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2053 - val_loss: 0.2087\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2109 - val_loss: 0.2098\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1967 - val_loss: 0.2209\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2091 - val_loss: 0.2099\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1958 - val_loss: 0.2132\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2037 - val_loss: 0.2053\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2109 - val_loss: 0.2065\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2028 - val_loss: 0.2084\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2098 - val_loss: 0.2103\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2062 - val_loss: 0.2147\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2026 - val_loss: 0.2089\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2027 - val_loss: 0.2093\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.2005 - val_loss: 0.2006\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1992 - val_loss: 0.2023\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2017 - val_loss: 0.2010\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1919 - val_loss: 0.1991\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2050 - val_loss: 0.2038\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.1969 - val_loss: 0.2003\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1933 - val_loss: 0.2048\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1962 - val_loss: 0.1957\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1967 - val_loss: 0.1983\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1905 - val_loss: 0.2014\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1946 - val_loss: 0.1952\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1939 - val_loss: 0.1965\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1913 - val_loss: 0.1951\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1908 - val_loss: 0.2042\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1925 - val_loss: 0.2028\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1881 - val_loss: 0.1950\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1904 - val_loss: 0.1912\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1898 - val_loss: 0.1924\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1925 - val_loss: 0.1975\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1907 - val_loss: 0.1948\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1928 - val_loss: 0.1906\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.1909 - val_loss: 0.1920\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1854 - val_loss: 0.1948\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1892 - val_loss: 0.1886\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1862 - val_loss: 0.1895\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1889 - val_loss: 0.1895\n",
      "Epoch 67/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1916 - val_loss: 0.1856\n",
      "Epoch 68/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1844 - val_loss: 0.1916\n",
      "Epoch 69/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1859 - val_loss: 0.1857\n",
      "Epoch 70/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1873 - val_loss: 0.1870\n",
      "Epoch 71/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1897 - val_loss: 0.1919\n",
      "Epoch 72/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1808 - val_loss: 0.1886\n",
      "Epoch 73/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1807 - val_loss: 0.1831\n",
      "Epoch 74/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1866 - val_loss: 0.1882\n",
      "Epoch 75/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1900 - val_loss: 0.1830\n",
      "Epoch 76/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1778 - val_loss: 0.1865\n",
      "Epoch 77/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1789 - val_loss: 0.1937\n",
      "Epoch 78/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1802 - val_loss: 0.1841\n",
      "Epoch 79/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1808 - val_loss: 0.1839\n",
      "Epoch 80/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1824 - val_loss: 0.1843\n",
      "Epoch 81/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1792 - val_loss: 0.1849\n",
      "Epoch 82/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.1762 - val_loss: 0.1844\n",
      "Epoch 83/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1827 - val_loss: 0.1834\n",
      "Epoch 84/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1806 - val_loss: 0.1832\n",
      "Epoch 85/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1841 - val_loss: 0.1881\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1844\n",
      "Hidden Layers: 2, Neurons 32\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - loss: 1.2339 - val_loss: 0.3355\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.3514 - val_loss: 0.3023\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2760 - val_loss: 0.2761\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2655 - val_loss: 0.2535\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2511 - val_loss: 0.2463\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2632 - val_loss: 0.2473\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2322 - val_loss: 0.2386\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2450 - val_loss: 0.2394\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2290 - val_loss: 0.2315\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2252 - val_loss: 0.2254\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2296 - val_loss: 0.2197\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.2304 - val_loss: 0.2195\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2155 - val_loss: 0.2238\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2118 - val_loss: 0.2198\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2116 - val_loss: 0.2233\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2134 - val_loss: 0.2227\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2053 - val_loss: 0.2072\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2017 - val_loss: 0.2081\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2040 - val_loss: 0.2096\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2174 - val_loss: 0.2080\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2003 - val_loss: 0.2133\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2051 - val_loss: 0.2086\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2065 - val_loss: 0.2072\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2006 - val_loss: 0.2024\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.2034 - val_loss: 0.2017\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1930 - val_loss: 0.2075\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1976 - val_loss: 0.1982\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1980 - val_loss: 0.2018\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1921 - val_loss: 0.1947\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.1951 - val_loss: 0.1941\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1957 - val_loss: 0.1935\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1832 - val_loss: 0.1990\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.2137 - val_loss: 0.2007\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1913 - val_loss: 0.1993\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1951 - val_loss: 0.1962\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1866 - val_loss: 0.1931\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1876 - val_loss: 0.1884\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1842 - val_loss: 0.1864\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1822 - val_loss: 0.1875\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1880 - val_loss: 0.1894\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.1867 - val_loss: 0.1883\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1783 - val_loss: 0.1977\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1902 - val_loss: 0.1840\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1797 - val_loss: 0.1841\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1845 - val_loss: 0.1838\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1822 - val_loss: 0.1786\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1772 - val_loss: 0.1796\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1810 - val_loss: 0.1811\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1741 - val_loss: 0.1904\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1776 - val_loss: 0.1746\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1723 - val_loss: 0.1747\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1712 - val_loss: 0.1731\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1743 - val_loss: 0.1716\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1717 - val_loss: 0.1787\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1643 - val_loss: 0.1713\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1723 - val_loss: 0.1674\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1683 - val_loss: 0.1748\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1623 - val_loss: 0.1678\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1694 - val_loss: 0.1650\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.1620 - val_loss: 0.1736\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1610 - val_loss: 0.1646\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1602 - val_loss: 0.1709\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1649 - val_loss: 0.1600\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1547 - val_loss: 0.1634\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1597 - val_loss: 0.1647\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1567 - val_loss: 0.1613\n",
      "Epoch 67/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1556 - val_loss: 0.1623\n",
      "Epoch 68/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1605 - val_loss: 0.1687\n",
      "Epoch 69/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.1638 - val_loss: 0.1596\n",
      "Epoch 70/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1559 - val_loss: 0.1655\n",
      "Epoch 71/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1612 - val_loss: 0.1623\n",
      "Epoch 72/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1545 - val_loss: 0.1586\n",
      "Epoch 73/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1573 - val_loss: 0.1693\n",
      "Epoch 74/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.1513 - val_loss: 0.1623\n",
      "Epoch 75/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1433 - val_loss: 0.1638\n",
      "Epoch 76/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1501 - val_loss: 0.1613\n",
      "Epoch 77/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1562 - val_loss: 0.1565\n",
      "Epoch 78/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1525 - val_loss: 0.1578\n",
      "Epoch 79/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1438 - val_loss: 0.1611\n",
      "Epoch 80/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1481 - val_loss: 0.1551\n",
      "Epoch 81/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1496 - val_loss: 0.1599\n",
      "Epoch 82/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1438 - val_loss: 0.1668\n",
      "Epoch 83/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1490 - val_loss: 0.1557\n",
      "Epoch 84/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1444 - val_loss: 0.1617\n",
      "Epoch 85/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.1490 - val_loss: 0.1584\n",
      "Epoch 86/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1443 - val_loss: 0.1572\n",
      "Epoch 87/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1416 - val_loss: 0.1593\n",
      "Epoch 88/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1492 - val_loss: 0.1612\n",
      "Epoch 89/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1472 - val_loss: 0.1534\n",
      "Epoch 90/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - loss: 0.1511 - val_loss: 0.1628\n",
      "Epoch 91/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1424 - val_loss: 0.1569\n",
      "Epoch 92/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - loss: 0.1407 - val_loss: 0.1595\n",
      "Epoch 93/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1427 - val_loss: 0.1592\n",
      "Epoch 94/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1392 - val_loss: 0.1586\n",
      "Epoch 95/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1408 - val_loss: 0.1608\n",
      "Epoch 96/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1432 - val_loss: 0.1589\n",
      "Epoch 97/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1339 - val_loss: 0.1599\n",
      "Epoch 98/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1392 - val_loss: 0.1566\n",
      "Epoch 99/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1368 - val_loss: 0.1574\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1554\n",
      "Hidden Layers: 2, Neurons 64\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 1.1374 - val_loss: 0.2868\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.2919 - val_loss: 0.2604\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2577 - val_loss: 0.2310\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.2532 - val_loss: 0.2365\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.2358 - val_loss: 0.2513\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.2252 - val_loss: 0.2275\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.2251 - val_loss: 0.2133\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.2238 - val_loss: 0.2134\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.2124 - val_loss: 0.2244\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.2105 - val_loss: 0.2130\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.2044 - val_loss: 0.2219\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.2018 - val_loss: 0.2213\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.2129 - val_loss: 0.2210\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2028 - val_loss: 0.2116\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1975 - val_loss: 0.1952\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1995 - val_loss: 0.2101\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 0.1955 - val_loss: 0.2089\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1998 - val_loss: 0.2151\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.2059 - val_loss: 0.1978\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1974 - val_loss: 0.2095\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1958 - val_loss: 0.1983\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1885 - val_loss: 0.1926\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1940 - val_loss: 0.1875\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 0.1925 - val_loss: 0.1918\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1873 - val_loss: 0.1881\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1822 - val_loss: 0.1856\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1879 - val_loss: 0.1860\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1873 - val_loss: 0.1906\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1857 - val_loss: 0.1852\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1873 - val_loss: 0.1912\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1858 - val_loss: 0.1883\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1892 - val_loss: 0.1833\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1808 - val_loss: 0.1839\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1850 - val_loss: 0.1817\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1848 - val_loss: 0.1807\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1788 - val_loss: 0.1832\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1790 - val_loss: 0.1817\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1715 - val_loss: 0.1799\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 0.1757 - val_loss: 0.1780\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1746 - val_loss: 0.1749\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1706 - val_loss: 0.1797\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1622 - val_loss: 0.1781\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1641 - val_loss: 0.1640\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1638 - val_loss: 0.1695\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1567 - val_loss: 0.1658\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1545 - val_loss: 0.1603\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1517 - val_loss: 0.1633\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1563 - val_loss: 0.1620\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1516 - val_loss: 0.1582\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1537 - val_loss: 0.1563\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1523 - val_loss: 0.1600\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1518 - val_loss: 0.1618\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1483 - val_loss: 0.1507\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1513 - val_loss: 0.1521\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1438 - val_loss: 0.1555\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1498 - val_loss: 0.1496\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1415 - val_loss: 0.1573\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1457 - val_loss: 0.1504\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1433 - val_loss: 0.1530\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1421 - val_loss: 0.1544\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1403 - val_loss: 0.1482\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1465 - val_loss: 0.1543\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1380 - val_loss: 0.1579\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1352 - val_loss: 0.1500\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1419 - val_loss: 0.1497\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1420 - val_loss: 0.1506\n",
      "Epoch 67/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1382 - val_loss: 0.1480\n",
      "Epoch 68/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 0.1361 - val_loss: 0.1529\n",
      "Epoch 69/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1367 - val_loss: 0.1529\n",
      "Epoch 70/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1302 - val_loss: 0.1545\n",
      "Epoch 71/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1351 - val_loss: 0.1559\n",
      "Epoch 72/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 0.1372 - val_loss: 0.1499\n",
      "Epoch 73/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1320 - val_loss: 0.1536\n",
      "Epoch 74/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1340 - val_loss: 0.1508\n",
      "Epoch 75/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1347 - val_loss: 0.1548\n",
      "Epoch 76/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1342 - val_loss: 0.1510\n",
      "Epoch 77/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.1281 - val_loss: 0.1499\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1563\n",
      "Hidden Layers: 2, Neurons 96\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 32ms/step - loss: 1.0659 - val_loss: 0.3514\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.3040 - val_loss: 0.2520\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2461 - val_loss: 0.2478\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2434 - val_loss: 0.2445\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - loss: 0.2377 - val_loss: 0.2192\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.2253 - val_loss: 0.2213\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.2224 - val_loss: 0.2224\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.2349 - val_loss: 0.2269\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.2190 - val_loss: 0.2127\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2076 - val_loss: 0.2236\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2151 - val_loss: 0.2060\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.2085 - val_loss: 0.2053\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.2049 - val_loss: 0.2060\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.2080 - val_loss: 0.2059\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2088 - val_loss: 0.2035\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2180 - val_loss: 0.2004\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.2076 - val_loss: 0.1993\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2015 - val_loss: 0.2096\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.2067 - val_loss: 0.2305\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.2069 - val_loss: 0.2135\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2110 - val_loss: 0.1953\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1986 - val_loss: 0.2018\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.2016 - val_loss: 0.2104\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.2015 - val_loss: 0.1967\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2000 - val_loss: 0.1988\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - loss: 0.1982 - val_loss: 0.1895\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1965 - val_loss: 0.1888\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1878 - val_loss: 0.1789\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1868 - val_loss: 0.1785\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1827 - val_loss: 0.1756\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.1742 - val_loss: 0.1704\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.1753 - val_loss: 0.1721\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1770 - val_loss: 0.1692\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1716 - val_loss: 0.1604\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.1749 - val_loss: 0.1602\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1706 - val_loss: 0.1621\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1615 - val_loss: 0.1600\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.1605 - val_loss: 0.1620\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1512 - val_loss: 0.1573\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1547 - val_loss: 0.1511\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.1536 - val_loss: 0.1536\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1546 - val_loss: 0.1561\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.1543 - val_loss: 0.1677\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.1534 - val_loss: 0.1564\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1453 - val_loss: 0.1551\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.1490 - val_loss: 0.1471\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.1489 - val_loss: 0.1480\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1500 - val_loss: 0.1464\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1468 - val_loss: 0.1499\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1476 - val_loss: 0.1497\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1388 - val_loss: 0.1591\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.1489 - val_loss: 0.1463\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1396 - val_loss: 0.1476\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1320 - val_loss: 0.1458\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1345 - val_loss: 0.1546\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.1353 - val_loss: 0.1564\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1326 - val_loss: 0.1445\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1379 - val_loss: 0.1590\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - loss: 0.1416 - val_loss: 0.1498\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1362 - val_loss: 0.1442\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1310 - val_loss: 0.1464\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.1300 - val_loss: 0.1429\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1345 - val_loss: 0.1443\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1320 - val_loss: 0.1477\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1367 - val_loss: 0.1419\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1301 - val_loss: 0.1478\n",
      "Epoch 67/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1289 - val_loss: 0.1437\n",
      "Epoch 68/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1276 - val_loss: 0.1469\n",
      "Epoch 69/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1313 - val_loss: 0.1467\n",
      "Epoch 70/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1272 - val_loss: 0.1427\n",
      "Epoch 71/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1306 - val_loss: 0.1448\n",
      "Epoch 72/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1235 - val_loss: 0.1485\n",
      "Epoch 73/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1276 - val_loss: 0.1528\n",
      "Epoch 74/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1238 - val_loss: 0.1476\n",
      "Epoch 75/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1242 - val_loss: 0.1490\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1494\n",
      "Hidden Layers: 2, Neurons 128\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 42ms/step - loss: 0.8996 - val_loss: 0.3302\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.2772 - val_loss: 0.2625\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.2544 - val_loss: 0.2335\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.2479 - val_loss: 0.2232\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.2279 - val_loss: 0.2189\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.2304 - val_loss: 0.2251\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.2060 - val_loss: 0.2145\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.2111 - val_loss: 0.2117\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.2065 - val_loss: 0.2039\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.2148 - val_loss: 0.2184\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.2012 - val_loss: 0.2019\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.2099 - val_loss: 0.2054\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - loss: 0.1988 - val_loss: 0.2175\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - loss: 0.2158 - val_loss: 0.2083\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - loss: 0.1963 - val_loss: 0.1985\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - loss: 0.1993 - val_loss: 0.2203\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.1987 - val_loss: 0.1955\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 42ms/step - loss: 0.1954 - val_loss: 0.1978\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1961 - val_loss: 0.1895\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.1887 - val_loss: 0.1890\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1930 - val_loss: 0.1857\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step - loss: 0.1911 - val_loss: 0.2059\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.1919 - val_loss: 0.1861\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1843 - val_loss: 0.1784\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1738 - val_loss: 0.1700\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - loss: 0.1734 - val_loss: 0.1693\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1672 - val_loss: 0.1645\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - loss: 0.1722 - val_loss: 0.1668\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1630 - val_loss: 0.1690\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.1670 - val_loss: 0.1661\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - loss: 0.1535 - val_loss: 0.1584\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1495 - val_loss: 0.1559\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1548 - val_loss: 0.1683\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1468 - val_loss: 0.1538\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1535 - val_loss: 0.1557\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1519 - val_loss: 0.1525\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1481 - val_loss: 0.1539\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1425 - val_loss: 0.1629\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - loss: 0.1408 - val_loss: 0.1566\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1512 - val_loss: 0.1595\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1455 - val_loss: 0.1506\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.1471 - val_loss: 0.1546\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - loss: 0.1423 - val_loss: 0.1471\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - loss: 0.1393 - val_loss: 0.1481\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1439 - val_loss: 0.1455\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1349 - val_loss: 0.1492\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1360 - val_loss: 0.1461\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.1366 - val_loss: 0.1461\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1386 - val_loss: 0.1473\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - loss: 0.1311 - val_loss: 0.1538\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1315 - val_loss: 0.1540\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1345 - val_loss: 0.1447\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step - loss: 0.1321 - val_loss: 0.1494\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - loss: 0.1255 - val_loss: 0.1497\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.1352 - val_loss: 0.1479\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1304 - val_loss: 0.1507\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1243 - val_loss: 0.1512\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.1254 - val_loss: 0.1507\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step - loss: 0.1246 - val_loss: 0.1520\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - loss: 0.1287 - val_loss: 0.1505\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - loss: 0.1214 - val_loss: 0.1593\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - loss: 0.1248 - val_loss: 0.1552\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1494\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = 2\n",
    "neurons = [16, 32, 64, 96, 128]\n",
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "for n in neurons:\n",
    "    print(f\"Hidden Layers: {hidden_layers}, Neurons {n}\"), \n",
    "    regressor, mse = initModel(hidden_layers, n, epochs, batch_size)\n",
    "    results.append({'MSE': mse, 'Hidden Layers': hidden_layers, 'Neurons': n, 'Model': regressor})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Neurons</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141757</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;Sequential name=sequential_3, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.141924</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;Sequential name=sequential_8, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144534</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;Sequential name=sequential_4, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.144724</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;Sequential name=sequential_9, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.145036</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_2, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.147063</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_1, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.148014</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_7, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.153365</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_6, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.168463</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.182994</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_5, built=True&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSE  Hidden Layers  Neurons  \\\n",
       "3  0.141757              1       96   \n",
       "8  0.141924              2       96   \n",
       "4  0.144534              1      128   \n",
       "9  0.144724              2      128   \n",
       "2  0.145036              1       64   \n",
       "1  0.147063              1       32   \n",
       "7  0.148014              2       64   \n",
       "6  0.153365              2       32   \n",
       "0  0.168463              1       16   \n",
       "5  0.182994              2       16   \n",
       "\n",
       "                                        Model  \n",
       "3  <Sequential name=sequential_3, built=True>  \n",
       "8  <Sequential name=sequential_8, built=True>  \n",
       "4  <Sequential name=sequential_4, built=True>  \n",
       "9  <Sequential name=sequential_9, built=True>  \n",
       "2  <Sequential name=sequential_2, built=True>  \n",
       "1  <Sequential name=sequential_1, built=True>  \n",
       "7  <Sequential name=sequential_7, built=True>  \n",
       "6  <Sequential name=sequential_6, built=True>  \n",
       "0    <Sequential name=sequential, built=True>  \n",
       "5  <Sequential name=sequential_5, built=True>  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "df_results.sort_values(by='MSE').head(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layers: 3, Neurons 16\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 1.6962 - val_loss: 0.5273\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.4375 - val_loss: 0.3173\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2956 - val_loss: 0.2798\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2861 - val_loss: 0.2625\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2645 - val_loss: 0.2508\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2491 - val_loss: 0.2662\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2466 - val_loss: 0.2456\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2316 - val_loss: 0.2894\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2454 - val_loss: 0.2523\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2382 - val_loss: 0.2475\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2405 - val_loss: 0.2545\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2372 - val_loss: 0.2453\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 0.2296 - val_loss: 0.2380\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 0.2286 - val_loss: 0.2322\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2265 - val_loss: 0.2364\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.2269 - val_loss: 0.2440\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2172 - val_loss: 0.2218\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2197 - val_loss: 0.2188\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2122 - val_loss: 0.2180\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 0.2097 - val_loss: 0.2272\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2177 - val_loss: 0.2182\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2165 - val_loss: 0.2138\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 0.2085 - val_loss: 0.2130\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 0.2062 - val_loss: 0.2097\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2095 - val_loss: 0.2195\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.2067 - val_loss: 0.2159\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.2133 - val_loss: 0.2049\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2108 - val_loss: 0.2079\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2061 - val_loss: 0.2080\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2106 - val_loss: 0.2130\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2029 - val_loss: 0.2084\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2059 - val_loss: 0.2017\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 0.2107 - val_loss: 0.2022\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2072 - val_loss: 0.1992\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 0.1990 - val_loss: 0.2002\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2063 - val_loss: 0.2088\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2051 - val_loss: 0.2128\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2019 - val_loss: 0.2024\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1982 - val_loss: 0.1983\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2018 - val_loss: 0.1959\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1996 - val_loss: 0.2010\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1942 - val_loss: 0.1979\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1922 - val_loss: 0.2067\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.2009 - val_loss: 0.2014\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1921 - val_loss: 0.1976\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1895 - val_loss: 0.2060\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.1936 - val_loss: 0.1925\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1859 - val_loss: 0.1909\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.1906 - val_loss: 0.1936\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1946 - val_loss: 0.1944\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 0.1929 - val_loss: 0.1986\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1931 - val_loss: 0.1873\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.1916 - val_loss: 0.1988\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1930 - val_loss: 0.1864\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.1911 - val_loss: 0.1920\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1861 - val_loss: 0.1893\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1879 - val_loss: 0.1874\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1902 - val_loss: 0.1856\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1793 - val_loss: 0.1873\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1789 - val_loss: 0.1886\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.1879 - val_loss: 0.1857\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1923 - val_loss: 0.1879\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1852 - val_loss: 0.1817\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1818 - val_loss: 0.1911\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1842 - val_loss: 0.1893\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1914 - val_loss: 0.1838\n",
      "Epoch 67/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1864 - val_loss: 0.1867\n",
      "Epoch 68/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1848 - val_loss: 0.1831\n",
      "Epoch 69/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1832 - val_loss: 0.1821\n",
      "Epoch 70/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1876 - val_loss: 0.1883\n",
      "Epoch 71/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1831 - val_loss: 0.1896\n",
      "Epoch 72/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 0.1967 - val_loss: 0.1848\n",
      "Epoch 73/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1805 - val_loss: 0.1796\n",
      "Epoch 74/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1835 - val_loss: 0.1782\n",
      "Epoch 75/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1807 - val_loss: 0.1894\n",
      "Epoch 76/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 0.1894 - val_loss: 0.1848\n",
      "Epoch 77/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1838 - val_loss: 0.1819\n",
      "Epoch 78/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.1780 - val_loss: 0.1837\n",
      "Epoch 79/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1738 - val_loss: 0.1805\n",
      "Epoch 80/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1853 - val_loss: 0.1808\n",
      "Epoch 81/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1806 - val_loss: 0.1800\n",
      "Epoch 82/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.1788 - val_loss: 0.1836\n",
      "Epoch 83/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1834 - val_loss: 0.1779\n",
      "Epoch 84/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1792 - val_loss: 0.1836\n",
      "Epoch 85/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1741 - val_loss: 0.1860\n",
      "Epoch 86/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1820 - val_loss: 0.1787\n",
      "Epoch 87/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1820 - val_loss: 0.1770\n",
      "Epoch 88/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1758 - val_loss: 0.1959\n",
      "Epoch 89/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1888 - val_loss: 0.1798\n",
      "Epoch 90/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1772 - val_loss: 0.1821\n",
      "Epoch 91/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1722 - val_loss: 0.1860\n",
      "Epoch 92/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1764 - val_loss: 0.1783\n",
      "Epoch 93/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1780 - val_loss: 0.1841\n",
      "Epoch 94/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1765 - val_loss: 0.1785\n",
      "Epoch 95/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1830 - val_loss: 0.1810\n",
      "Epoch 96/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1808 - val_loss: 0.1783\n",
      "Epoch 97/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1733 - val_loss: 0.1769\n",
      "Epoch 98/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1777 - val_loss: 0.1758\n",
      "Epoch 99/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1729 - val_loss: 0.1757\n",
      "Epoch 100/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1778 - val_loss: 0.1817\n",
      "Epoch 101/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1840 - val_loss: 0.1765\n",
      "Epoch 102/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1757 - val_loss: 0.1787\n",
      "Epoch 103/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.1745 - val_loss: 0.1748\n",
      "Epoch 104/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1694 - val_loss: 0.1778\n",
      "Epoch 105/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1704 - val_loss: 0.1790\n",
      "Epoch 106/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1801 - val_loss: 0.1755\n",
      "Epoch 107/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1709 - val_loss: 0.1754\n",
      "Epoch 108/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1717 - val_loss: 0.1744\n",
      "Epoch 109/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1822 - val_loss: 0.1710\n",
      "Epoch 110/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1728 - val_loss: 0.1787\n",
      "Epoch 111/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1712 - val_loss: 0.1729\n",
      "Epoch 112/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1750 - val_loss: 0.1698\n",
      "Epoch 113/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - loss: 0.1713 - val_loss: 0.1779\n",
      "Epoch 114/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 0.1650 - val_loss: 0.1763\n",
      "Epoch 115/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - loss: 0.1731 - val_loss: 0.1733\n",
      "Epoch 116/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1682 - val_loss: 0.1737\n",
      "Epoch 117/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1716 - val_loss: 0.1748\n",
      "Epoch 118/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1718 - val_loss: 0.1709\n",
      "Epoch 119/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1697 - val_loss: 0.1731\n",
      "Epoch 120/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1817 - val_loss: 0.1727\n",
      "Epoch 121/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1712 - val_loss: 0.1720\n",
      "Epoch 122/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 0.1648 - val_loss: 0.1703\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1719\n",
      "Hidden Layers: 3, Neurons 32\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - loss: 1.1469 - val_loss: 0.5479\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.3888 - val_loss: 0.3291\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.2885 - val_loss: 0.2479\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.2609 - val_loss: 0.2699\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.2510 - val_loss: 0.2474\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.2333 - val_loss: 0.2190\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.2222 - val_loss: 0.2284\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.2224 - val_loss: 0.2294\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.2210 - val_loss: 0.2169\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.2196 - val_loss: 0.2156\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.2103 - val_loss: 0.2091\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.2125 - val_loss: 0.2184\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.2102 - val_loss: 0.2125\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.2059 - val_loss: 0.2090\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.2095 - val_loss: 0.2100\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.2077 - val_loss: 0.2193\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.2088 - val_loss: 0.2062\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1931 - val_loss: 0.2193\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.2044 - val_loss: 0.2112\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1918 - val_loss: 0.2212\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 0.2028 - val_loss: 0.2062\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.2037 - val_loss: 0.2130\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1901 - val_loss: 0.1994\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1940 - val_loss: 0.2031\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 0.1963 - val_loss: 0.1989\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1951 - val_loss: 0.2061\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.2007 - val_loss: 0.2046\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1858 - val_loss: 0.1974\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1947 - val_loss: 0.2036\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1895 - val_loss: 0.1907\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1947 - val_loss: 0.1960\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1937 - val_loss: 0.1905\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1869 - val_loss: 0.1974\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1869 - val_loss: 0.1971\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1866 - val_loss: 0.1931\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1847 - val_loss: 0.1887\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1872 - val_loss: 0.1898\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1800 - val_loss: 0.1978\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1907 - val_loss: 0.1936\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1834 - val_loss: 0.1833\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1847 - val_loss: 0.1850\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1810 - val_loss: 0.1933\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1858 - val_loss: 0.1972\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1926 - val_loss: 0.1875\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1896 - val_loss: 0.1867\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1863 - val_loss: 0.1796\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1885 - val_loss: 0.1852\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1834 - val_loss: 0.1951\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1770 - val_loss: 0.1807\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1699 - val_loss: 0.1775\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1707 - val_loss: 0.1832\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1733 - val_loss: 0.1835\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1741 - val_loss: 0.1783\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1786 - val_loss: 0.1823\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1738 - val_loss: 0.1762\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1786 - val_loss: 0.1727\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1747 - val_loss: 0.1749\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1757 - val_loss: 0.1720\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1649 - val_loss: 0.1771\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1744 - val_loss: 0.1760\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1762 - val_loss: 0.1739\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1631 - val_loss: 0.1771\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1683 - val_loss: 0.1690\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1631 - val_loss: 0.1634\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1598 - val_loss: 0.1682\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1654 - val_loss: 0.1673\n",
      "Epoch 67/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1586 - val_loss: 0.1702\n",
      "Epoch 68/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1617 - val_loss: 0.1679\n",
      "Epoch 69/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1505 - val_loss: 0.1656\n",
      "Epoch 70/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1562 - val_loss: 0.1644\n",
      "Epoch 71/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1543 - val_loss: 0.1658\n",
      "Epoch 72/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1577 - val_loss: 0.1666\n",
      "Epoch 73/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1630 - val_loss: 0.1619\n",
      "Epoch 74/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1571 - val_loss: 0.1624\n",
      "Epoch 75/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1514 - val_loss: 0.1597\n",
      "Epoch 76/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1549 - val_loss: 0.1593\n",
      "Epoch 77/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1523 - val_loss: 0.1625\n",
      "Epoch 78/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1582 - val_loss: 0.1558\n",
      "Epoch 79/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1508 - val_loss: 0.1591\n",
      "Epoch 80/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1474 - val_loss: 0.1589\n",
      "Epoch 81/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - loss: 0.1536 - val_loss: 0.1561\n",
      "Epoch 82/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1485 - val_loss: 0.1581\n",
      "Epoch 83/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1459 - val_loss: 0.1609\n",
      "Epoch 84/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1503 - val_loss: 0.1594\n",
      "Epoch 85/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1490 - val_loss: 0.1553\n",
      "Epoch 86/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1435 - val_loss: 0.1563\n",
      "Epoch 87/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1450 - val_loss: 0.1579\n",
      "Epoch 88/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1462 - val_loss: 0.1557\n",
      "Epoch 89/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1386 - val_loss: 0.1589\n",
      "Epoch 90/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1418 - val_loss: 0.1542\n",
      "Epoch 91/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1377 - val_loss: 0.1530\n",
      "Epoch 92/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1359 - val_loss: 0.1569\n",
      "Epoch 93/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1410 - val_loss: 0.1537\n",
      "Epoch 94/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1384 - val_loss: 0.1527\n",
      "Epoch 95/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1411 - val_loss: 0.1539\n",
      "Epoch 96/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1432 - val_loss: 0.1542\n",
      "Epoch 97/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1412 - val_loss: 0.1544\n",
      "Epoch 98/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1362 - val_loss: 0.1600\n",
      "Epoch 99/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1402 - val_loss: 0.1581\n",
      "Epoch 100/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1436 - val_loss: 0.1521\n",
      "Epoch 101/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1412 - val_loss: 0.1537\n",
      "Epoch 102/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1335 - val_loss: 0.1539\n",
      "Epoch 103/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1308 - val_loss: 0.1508\n",
      "Epoch 104/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1390 - val_loss: 0.1546\n",
      "Epoch 105/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1410 - val_loss: 0.1549\n",
      "Epoch 106/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1361 - val_loss: 0.1526\n",
      "Epoch 107/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1324 - val_loss: 0.1553\n",
      "Epoch 108/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1349 - val_loss: 0.1550\n",
      "Epoch 109/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1396 - val_loss: 0.1524\n",
      "Epoch 110/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1360 - val_loss: 0.1533\n",
      "Epoch 111/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1322 - val_loss: 0.1501\n",
      "Epoch 112/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1361 - val_loss: 0.1531\n",
      "Epoch 113/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1343 - val_loss: 0.1528\n",
      "Epoch 114/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1282 - val_loss: 0.1521\n",
      "Epoch 115/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1311 - val_loss: 0.1588\n",
      "Epoch 116/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1373 - val_loss: 0.1553\n",
      "Epoch 117/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1320 - val_loss: 0.1559\n",
      "Epoch 118/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1357 - val_loss: 0.1506\n",
      "Epoch 119/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1310 - val_loss: 0.1540\n",
      "Epoch 120/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1301 - val_loss: 0.1529\n",
      "Epoch 121/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1235 - val_loss: 0.1486\n",
      "Epoch 122/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1223 - val_loss: 0.1503\n",
      "Epoch 123/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.1273 - val_loss: 0.1519\n",
      "Epoch 124/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1338 - val_loss: 0.1558\n",
      "Epoch 125/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1242 - val_loss: 0.1532\n",
      "Epoch 126/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1263 - val_loss: 0.1558\n",
      "Epoch 127/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1275 - val_loss: 0.1595\n",
      "Epoch 128/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1298 - val_loss: 0.1549\n",
      "Epoch 129/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1263 - val_loss: 0.1579\n",
      "Epoch 130/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1250 - val_loss: 0.1549\n",
      "Epoch 131/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 0.1239 - val_loss: 0.1539\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1551\n",
      "Hidden Layers: 3, Neurons 64\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 37ms/step - loss: 0.9951 - val_loss: 0.3577\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.3109 - val_loss: 0.2559\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2460 - val_loss: 0.2519\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.2329 - val_loss: 0.2323\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - loss: 0.2283 - val_loss: 0.2363\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2315 - val_loss: 0.2435\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2182 - val_loss: 0.2232\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2214 - val_loss: 0.2189\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2123 - val_loss: 0.2197\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.2198 - val_loss: 0.2232\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2112 - val_loss: 0.2075\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2116 - val_loss: 0.2092\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2023 - val_loss: 0.2086\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.2016 - val_loss: 0.2050\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2073 - val_loss: 0.2093\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2087 - val_loss: 0.2061\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2000 - val_loss: 0.1965\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1975 - val_loss: 0.2141\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2084 - val_loss: 0.2264\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.2062 - val_loss: 0.1948\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1971 - val_loss: 0.2009\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1916 - val_loss: 0.1938\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1816 - val_loss: 0.1936\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1869 - val_loss: 0.1982\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1950 - val_loss: 0.1920\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - loss: 0.1832 - val_loss: 0.1919\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1874 - val_loss: 0.1852\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1837 - val_loss: 0.1867\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1857 - val_loss: 0.1979\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1839 - val_loss: 0.2015\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1871 - val_loss: 0.1831\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1810 - val_loss: 0.1789\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1738 - val_loss: 0.1853\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1676 - val_loss: 0.1785\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1709 - val_loss: 0.1676\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1733 - val_loss: 0.1739\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1641 - val_loss: 0.1681\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - loss: 0.1659 - val_loss: 0.1688\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1688 - val_loss: 0.1648\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.1564 - val_loss: 0.1641\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1596 - val_loss: 0.1659\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1528 - val_loss: 0.1641\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1487 - val_loss: 0.1592\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1532 - val_loss: 0.1624\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1578 - val_loss: 0.1580\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1463 - val_loss: 0.1583\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1497 - val_loss: 0.1597\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1476 - val_loss: 0.1568\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1485 - val_loss: 0.1497\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1560 - val_loss: 0.1579\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1512 - val_loss: 0.1527\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.1434 - val_loss: 0.1622\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1446 - val_loss: 0.1623\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1428 - val_loss: 0.1461\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1459 - val_loss: 0.1596\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1434 - val_loss: 0.1515\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1368 - val_loss: 0.1461\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1404 - val_loss: 0.1474\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1446 - val_loss: 0.1469\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1409 - val_loss: 0.1435\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.1359 - val_loss: 0.1464\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1359 - val_loss: 0.1462\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1381 - val_loss: 0.1476\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1371 - val_loss: 0.1510\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1322 - val_loss: 0.1468\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1364 - val_loss: 0.1473\n",
      "Epoch 67/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1360 - val_loss: 0.1458\n",
      "Epoch 68/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.1360 - val_loss: 0.1442\n",
      "Epoch 69/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1374 - val_loss: 0.1424\n",
      "Epoch 70/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1273 - val_loss: 0.1458\n",
      "Epoch 71/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1390 - val_loss: 0.1466\n",
      "Epoch 72/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1267 - val_loss: 0.1473\n",
      "Epoch 73/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1279 - val_loss: 0.1513\n",
      "Epoch 74/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1345 - val_loss: 0.1481\n",
      "Epoch 75/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1315 - val_loss: 0.1451\n",
      "Epoch 76/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1260 - val_loss: 0.1470\n",
      "Epoch 77/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1296 - val_loss: 0.1512\n",
      "Epoch 78/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1289 - val_loss: 0.1487\n",
      "Epoch 79/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1272 - val_loss: 0.1472\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1477\n",
      "Hidden Layers: 3, Neurons 96\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 47ms/step - loss: 0.9478 - val_loss: 0.2860\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.2743 - val_loss: 0.2556\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.2469 - val_loss: 0.2498\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 46ms/step - loss: 0.2409 - val_loss: 0.2200\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.2244 - val_loss: 0.2223\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.2147 - val_loss: 0.2225\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.2237 - val_loss: 0.2274\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.2192 - val_loss: 0.2126\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.2213 - val_loss: 0.2133\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.2116 - val_loss: 0.2072\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.2002 - val_loss: 0.2035\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.2045 - val_loss: 0.1954\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1875 - val_loss: 0.1996\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.2041 - val_loss: 0.2930\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.2075 - val_loss: 0.2004\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.2102 - val_loss: 0.2577\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.2022 - val_loss: 0.1906\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.1885 - val_loss: 0.1931\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - loss: 0.1904 - val_loss: 0.1946\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.1936 - val_loss: 0.1912\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1811 - val_loss: 0.2147\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1938 - val_loss: 0.1900\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1868 - val_loss: 0.1880\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1886 - val_loss: 0.2067\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.2042 - val_loss: 0.1914\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.1838 - val_loss: 0.1889\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1800 - val_loss: 0.1795\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1774 - val_loss: 0.1812\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1780 - val_loss: 0.1806\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1717 - val_loss: 0.1863\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1786 - val_loss: 0.1756\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.1769 - val_loss: 0.1927\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1737 - val_loss: 0.1790\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.1748 - val_loss: 0.1686\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.1664 - val_loss: 0.1655\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1627 - val_loss: 0.1682\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1632 - val_loss: 0.1642\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1565 - val_loss: 0.1666\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.1589 - val_loss: 0.1575\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.1508 - val_loss: 0.1543\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.1451 - val_loss: 0.1524\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.1466 - val_loss: 0.1552\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1455 - val_loss: 0.1586\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1536 - val_loss: 0.1505\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.1466 - val_loss: 0.1547\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.1452 - val_loss: 0.1470\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1467 - val_loss: 0.1484\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1415 - val_loss: 0.1506\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 46ms/step - loss: 0.1396 - val_loss: 0.1455\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.1394 - val_loss: 0.1496\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1402 - val_loss: 0.1521\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1359 - val_loss: 0.1579\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1358 - val_loss: 0.1496\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1399 - val_loss: 0.1498\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1374 - val_loss: 0.1486\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - loss: 0.1345 - val_loss: 0.1466\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.1315 - val_loss: 0.1466\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.1361 - val_loss: 0.1485\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 47ms/step - loss: 0.1298 - val_loss: 0.1512\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1535\n",
      "Hidden Layers: 3, Neurons 128\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 62ms/step - loss: 0.9017 - val_loss: 0.2714\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.2566 - val_loss: 0.2498\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.2436 - val_loss: 0.2593\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.2532 - val_loss: 0.2280\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - loss: 0.2301 - val_loss: 0.2206\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.2176 - val_loss: 0.2175\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.2340 - val_loss: 0.2315\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.2147 - val_loss: 0.2192\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - loss: 0.2156 - val_loss: 0.2137\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - loss: 0.2136 - val_loss: 0.2408\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.2112 - val_loss: 0.2045\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.1945 - val_loss: 0.1999\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.2055 - val_loss: 0.2005\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.1992 - val_loss: 0.1980\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.1965 - val_loss: 0.2021\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - loss: 0.1940 - val_loss: 0.2155\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.1967 - val_loss: 0.2086\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 64ms/step - loss: 0.1945 - val_loss: 0.1971\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.1879 - val_loss: 0.2084\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 64ms/step - loss: 0.1963 - val_loss: 0.1883\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 64ms/step - loss: 0.1869 - val_loss: 0.1878\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - loss: 0.1871 - val_loss: 0.1929\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.1944 - val_loss: 0.1793\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - loss: 0.1823 - val_loss: 0.1754\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.1786 - val_loss: 0.1751\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.1734 - val_loss: 0.1773\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.1758 - val_loss: 0.1813\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.1712 - val_loss: 0.1757\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.1696 - val_loss: 0.1764\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.1562 - val_loss: 0.1599\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.1574 - val_loss: 0.1654\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - loss: 0.1637 - val_loss: 0.1609\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.1499 - val_loss: 0.1524\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.1524 - val_loss: 0.1537\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.1492 - val_loss: 0.1541\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.1489 - val_loss: 0.1535\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.1474 - val_loss: 0.1598\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - loss: 0.1464 - val_loss: 0.1552\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.1456 - val_loss: 0.1519\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - loss: 0.1426 - val_loss: 0.1469\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - loss: 0.1407 - val_loss: 0.1547\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.1577 - val_loss: 0.1546\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - loss: 0.1368 - val_loss: 0.1474\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.1401 - val_loss: 0.1503\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - loss: 0.1349 - val_loss: 0.1446\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.1369 - val_loss: 0.1461\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 63ms/step - loss: 0.1362 - val_loss: 0.1432\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.1334 - val_loss: 0.1458\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - loss: 0.1301 - val_loss: 0.1472\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.1324 - val_loss: 0.1488\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.1265 - val_loss: 0.1476\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.1315 - val_loss: 0.1470\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - loss: 0.1268 - val_loss: 0.1518\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.1305 - val_loss: 0.1604\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.1425 - val_loss: 0.1468\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 62ms/step - loss: 0.1199 - val_loss: 0.1452\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 61ms/step - loss: 0.1255 - val_loss: 0.1538\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.1481\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = 3\n",
    "neurons = [16, 32, 64, 96, 128]\n",
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "for n in neurons:\n",
    "    print(f\"Hidden Layers: {hidden_layers}, Neurons {n}\"), \n",
    "    regressor, mse = initModel(hidden_layers, n, epochs, batch_size)\n",
    "    results.append({'MSE': mse, 'Hidden Layers': hidden_layers, 'Neurons': n, 'Model': regressor})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Neurons</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141757</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;Sequential name=sequential_3, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.141924</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;Sequential name=sequential_8, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.142399</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_12, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.143165</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;Sequential name=sequential_14, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144534</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;Sequential name=sequential_4, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.144724</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;Sequential name=sequential_9, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.145036</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_2, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.145470</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;Sequential name=sequential_13, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.147063</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_1, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.148014</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_7, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.148603</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_11, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.153365</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_6, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.168463</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.169782</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_10, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.182994</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_5, built=True&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MSE  Hidden Layers  Neurons  \\\n",
       "3   0.141757              1       96   \n",
       "8   0.141924              2       96   \n",
       "12  0.142399              3       64   \n",
       "14  0.143165              3      128   \n",
       "4   0.144534              1      128   \n",
       "9   0.144724              2      128   \n",
       "2   0.145036              1       64   \n",
       "13  0.145470              3       96   \n",
       "1   0.147063              1       32   \n",
       "7   0.148014              2       64   \n",
       "11  0.148603              3       32   \n",
       "6   0.153365              2       32   \n",
       "0   0.168463              1       16   \n",
       "10  0.169782              3       16   \n",
       "5   0.182994              2       16   \n",
       "\n",
       "                                          Model  \n",
       "3    <Sequential name=sequential_3, built=True>  \n",
       "8    <Sequential name=sequential_8, built=True>  \n",
       "12  <Sequential name=sequential_12, built=True>  \n",
       "14  <Sequential name=sequential_14, built=True>  \n",
       "4    <Sequential name=sequential_4, built=True>  \n",
       "9    <Sequential name=sequential_9, built=True>  \n",
       "2    <Sequential name=sequential_2, built=True>  \n",
       "13  <Sequential name=sequential_13, built=True>  \n",
       "1    <Sequential name=sequential_1, built=True>  \n",
       "7    <Sequential name=sequential_7, built=True>  \n",
       "11  <Sequential name=sequential_11, built=True>  \n",
       "6    <Sequential name=sequential_6, built=True>  \n",
       "0      <Sequential name=sequential, built=True>  \n",
       "10  <Sequential name=sequential_10, built=True>  \n",
       "5    <Sequential name=sequential_5, built=True>  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "df_results.sort_values(by='MSE').head(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layers: 4, Neurons 16\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 32ms/step - loss: 1.4795 - val_loss: 0.5478\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.5322 - val_loss: 0.3206\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.3019 - val_loss: 0.2833\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2759 - val_loss: 0.2555\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2623 - val_loss: 0.2463\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2498 - val_loss: 0.2520\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2379 - val_loss: 0.2406\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.2367 - val_loss: 0.2384\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2367 - val_loss: 0.2346\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2325 - val_loss: 0.2360\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2335 - val_loss: 0.2319\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2286 - val_loss: 0.2249\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2201 - val_loss: 0.2407\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2258 - val_loss: 0.2260\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2221 - val_loss: 0.2277\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2324 - val_loss: 0.2191\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2108 - val_loss: 0.2159\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2110 - val_loss: 0.2288\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2185 - val_loss: 0.2218\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2138 - val_loss: 0.2178\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2087 - val_loss: 0.2222\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2060 - val_loss: 0.2141\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2169 - val_loss: 0.2159\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1959 - val_loss: 0.2084\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2068 - val_loss: 0.2031\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - loss: 0.2067 - val_loss: 0.2065\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1985 - val_loss: 0.1983\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - loss: 0.1925 - val_loss: 0.2036\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1962 - val_loss: 0.1979\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1941 - val_loss: 0.2012\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1946 - val_loss: 0.1973\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - loss: 0.1981 - val_loss: 0.1978\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1948 - val_loss: 0.1970\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1953 - val_loss: 0.2041\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1911 - val_loss: 0.2062\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1966 - val_loss: 0.2065\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2069 - val_loss: 0.1944\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1982 - val_loss: 0.1933\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1894 - val_loss: 0.1955\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1902 - val_loss: 0.2002\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.1913 - val_loss: 0.1983\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1901 - val_loss: 0.1976\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1913 - val_loss: 0.1929\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1871 - val_loss: 0.1958\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1882 - val_loss: 0.1910\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1839 - val_loss: 0.1851\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1856 - val_loss: 0.1890\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - loss: 0.1879 - val_loss: 0.1864\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1826 - val_loss: 0.1905\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1864 - val_loss: 0.1874\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1865 - val_loss: 0.1877\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1812 - val_loss: 0.1919\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1877 - val_loss: 0.1859\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1826 - val_loss: 0.1881\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1924 - val_loss: 0.1822\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1827 - val_loss: 0.1842\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1908 - val_loss: 0.1897\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1862 - val_loss: 0.1925\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1801 - val_loss: 0.1842\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1803 - val_loss: 0.1822\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1804 - val_loss: 0.1911\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 0.1842 - val_loss: 0.1850\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1777 - val_loss: 0.1781\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1783 - val_loss: 0.1824\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - loss: 0.1825 - val_loss: 0.1807\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1817 - val_loss: 0.1819\n",
      "Epoch 67/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1820 - val_loss: 0.1794\n",
      "Epoch 68/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1782 - val_loss: 0.1820\n",
      "Epoch 69/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1722 - val_loss: 0.1798\n",
      "Epoch 70/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1742 - val_loss: 0.1854\n",
      "Epoch 71/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - loss: 0.1802 - val_loss: 0.1801\n",
      "Epoch 72/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1784 - val_loss: 0.1772\n",
      "Epoch 73/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1757 - val_loss: 0.1785\n",
      "Epoch 74/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1772 - val_loss: 0.1754\n",
      "Epoch 75/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1813 - val_loss: 0.1780\n",
      "Epoch 76/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1822 - val_loss: 0.1772\n",
      "Epoch 77/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1753 - val_loss: 0.1765\n",
      "Epoch 78/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1751 - val_loss: 0.1733\n",
      "Epoch 79/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1706 - val_loss: 0.1756\n",
      "Epoch 80/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1695 - val_loss: 0.1760\n",
      "Epoch 81/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1698 - val_loss: 0.1693\n",
      "Epoch 82/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1708 - val_loss: 0.1713\n",
      "Epoch 83/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1675 - val_loss: 0.1685\n",
      "Epoch 84/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1698 - val_loss: 0.1701\n",
      "Epoch 85/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1675 - val_loss: 0.1727\n",
      "Epoch 86/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1669 - val_loss: 0.1698\n",
      "Epoch 87/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1643 - val_loss: 0.1689\n",
      "Epoch 88/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1614 - val_loss: 0.1752\n",
      "Epoch 89/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - loss: 0.1606 - val_loss: 0.1676\n",
      "Epoch 90/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1547 - val_loss: 0.1671\n",
      "Epoch 91/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1596 - val_loss: 0.1644\n",
      "Epoch 92/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1589 - val_loss: 0.1640\n",
      "Epoch 93/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1544 - val_loss: 0.1634\n",
      "Epoch 94/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1631 - val_loss: 0.1654\n",
      "Epoch 95/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1616 - val_loss: 0.1625\n",
      "Epoch 96/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1535 - val_loss: 0.1599\n",
      "Epoch 97/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1547 - val_loss: 0.1590\n",
      "Epoch 98/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1496 - val_loss: 0.1620\n",
      "Epoch 99/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1558 - val_loss: 0.1632\n",
      "Epoch 100/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1507 - val_loss: 0.1637\n",
      "Epoch 101/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1539 - val_loss: 0.1690\n",
      "Epoch 102/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1535 - val_loss: 0.1592\n",
      "Epoch 103/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1529 - val_loss: 0.1591\n",
      "Epoch 104/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1547 - val_loss: 0.1572\n",
      "Epoch 105/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1450 - val_loss: 0.1562\n",
      "Epoch 106/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1564 - val_loss: 0.1568\n",
      "Epoch 107/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1469 - val_loss: 0.1601\n",
      "Epoch 108/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1501 - val_loss: 0.1608\n",
      "Epoch 109/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1466 - val_loss: 0.1648\n",
      "Epoch 110/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1576 - val_loss: 0.1608\n",
      "Epoch 111/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1526 - val_loss: 0.1553\n",
      "Epoch 112/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - loss: 0.1493 - val_loss: 0.1590\n",
      "Epoch 113/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1575 - val_loss: 0.1549\n",
      "Epoch 114/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1434 - val_loss: 0.1549\n",
      "Epoch 115/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1409 - val_loss: 0.1559\n",
      "Epoch 116/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1470 - val_loss: 0.1568\n",
      "Epoch 117/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1455 - val_loss: 0.1546\n",
      "Epoch 118/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1423 - val_loss: 0.1589\n",
      "Epoch 119/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1460 - val_loss: 0.1566\n",
      "Epoch 120/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1407 - val_loss: 0.1578\n",
      "Epoch 121/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1457 - val_loss: 0.1571\n",
      "Epoch 122/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1442 - val_loss: 0.1571\n",
      "Epoch 123/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1424 - val_loss: 0.1566\n",
      "Epoch 124/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1440 - val_loss: 0.1579\n",
      "Epoch 125/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1421 - val_loss: 0.1584\n",
      "Epoch 126/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1453 - val_loss: 0.1556\n",
      "Epoch 127/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1428 - val_loss: 0.1543\n",
      "Epoch 128/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1452 - val_loss: 0.1549\n",
      "Epoch 129/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1468 - val_loss: 0.1530\n",
      "Epoch 130/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1446 - val_loss: 0.1564\n",
      "Epoch 131/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1478 - val_loss: 0.1548\n",
      "Epoch 132/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1417 - val_loss: 0.1552\n",
      "Epoch 133/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - loss: 0.1452 - val_loss: 0.1549\n",
      "Epoch 134/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1420 - val_loss: 0.1510\n",
      "Epoch 135/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1403 - val_loss: 0.1529\n",
      "Epoch 136/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1417 - val_loss: 0.1546\n",
      "Epoch 137/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1461 - val_loss: 0.1547\n",
      "Epoch 138/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1453 - val_loss: 0.1579\n",
      "Epoch 139/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1369 - val_loss: 0.1528\n",
      "Epoch 140/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1379 - val_loss: 0.1539\n",
      "Epoch 141/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1388 - val_loss: 0.1559\n",
      "Epoch 142/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1463 - val_loss: 0.1550\n",
      "Epoch 143/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1441 - val_loss: 0.1610\n",
      "Epoch 144/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - loss: 0.1405 - val_loss: 0.1562\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1553\n",
      "Hidden Layers: 4, Neurons 32\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 37ms/step - loss: 1.1916 - val_loss: 0.3443\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.3215 - val_loss: 0.2833\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.2623 - val_loss: 0.2551\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.2659 - val_loss: 0.2410\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.2353 - val_loss: 0.2444\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.2305 - val_loss: 0.2246\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2113 - val_loss: 0.2225\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.2154 - val_loss: 0.2121\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.2105 - val_loss: 0.2809\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.2241 - val_loss: 0.2378\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.2133 - val_loss: 0.2078\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2087 - val_loss: 0.2096\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2023 - val_loss: 0.2043\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2119 - val_loss: 0.2082\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.1994 - val_loss: 0.2004\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2012 - val_loss: 0.2027\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1960 - val_loss: 0.2079\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1932 - val_loss: 0.2093\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.2005 - val_loss: 0.2021\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1947 - val_loss: 0.2031\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1956 - val_loss: 0.2038\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1959 - val_loss: 0.2039\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.2006 - val_loss: 0.2022\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2019 - val_loss: 0.2009\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1932 - val_loss: 0.1951\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.1968 - val_loss: 0.1926\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1917 - val_loss: 0.1938\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.1869 - val_loss: 0.1900\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1895 - val_loss: 0.1910\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1968 - val_loss: 0.1878\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1875 - val_loss: 0.1947\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1887 - val_loss: 0.1889\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1884 - val_loss: 0.1883\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1813 - val_loss: 0.1948\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1866 - val_loss: 0.1891\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.1861 - val_loss: 0.1896\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1857 - val_loss: 0.1909\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1798 - val_loss: 0.1859\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1778 - val_loss: 0.2038\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1914 - val_loss: 0.1833\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.1721 - val_loss: 0.1865\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1840 - val_loss: 0.1799\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1746 - val_loss: 0.1774\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1773 - val_loss: 0.1755\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.1737 - val_loss: 0.1763\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1777 - val_loss: 0.1700\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1670 - val_loss: 0.1778\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1725 - val_loss: 0.1738\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.1706 - val_loss: 0.1809\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.1677 - val_loss: 0.1768\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.1668 - val_loss: 0.1669\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1675 - val_loss: 0.1682\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1676 - val_loss: 0.1683\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1658 - val_loss: 0.1694\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1563 - val_loss: 0.1677\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1598 - val_loss: 0.1621\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1611 - val_loss: 0.1640\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1628 - val_loss: 0.1655\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1590 - val_loss: 0.1657\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1568 - val_loss: 0.1681\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1579 - val_loss: 0.1598\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1534 - val_loss: 0.1634\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1519 - val_loss: 0.1725\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1569 - val_loss: 0.1611\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1539 - val_loss: 0.1657\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1514 - val_loss: 0.1572\n",
      "Epoch 67/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1481 - val_loss: 0.1571\n",
      "Epoch 68/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1511 - val_loss: 0.1621\n",
      "Epoch 69/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.1464 - val_loss: 0.1580\n",
      "Epoch 70/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1506 - val_loss: 0.1584\n",
      "Epoch 71/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1468 - val_loss: 0.1557\n",
      "Epoch 72/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1461 - val_loss: 0.1604\n",
      "Epoch 73/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1507 - val_loss: 0.1558\n",
      "Epoch 74/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1470 - val_loss: 0.1580\n",
      "Epoch 75/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1467 - val_loss: 0.1564\n",
      "Epoch 76/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1463 - val_loss: 0.1550\n",
      "Epoch 77/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1461 - val_loss: 0.1593\n",
      "Epoch 78/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1516 - val_loss: 0.1526\n",
      "Epoch 79/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1416 - val_loss: 0.1566\n",
      "Epoch 80/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1447 - val_loss: 0.1570\n",
      "Epoch 81/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1437 - val_loss: 0.1591\n",
      "Epoch 82/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1362 - val_loss: 0.1554\n",
      "Epoch 83/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.1433 - val_loss: 0.1519\n",
      "Epoch 84/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1369 - val_loss: 0.1567\n",
      "Epoch 85/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1362 - val_loss: 0.1515\n",
      "Epoch 86/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1402 - val_loss: 0.1523\n",
      "Epoch 87/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1395 - val_loss: 0.1492\n",
      "Epoch 88/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1349 - val_loss: 0.1512\n",
      "Epoch 89/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1420 - val_loss: 0.1568\n",
      "Epoch 90/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1322 - val_loss: 0.1558\n",
      "Epoch 91/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1386 - val_loss: 0.1528\n",
      "Epoch 92/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1383 - val_loss: 0.1514\n",
      "Epoch 93/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.1300 - val_loss: 0.1530\n",
      "Epoch 94/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.1375 - val_loss: 0.1499\n",
      "Epoch 95/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1289 - val_loss: 0.1566\n",
      "Epoch 96/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1383 - val_loss: 0.1496\n",
      "Epoch 97/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.1317 - val_loss: 0.1514\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1540\n",
      "Hidden Layers: 4, Neurons 64\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 53ms/step - loss: 0.9723 - val_loss: 0.3141\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.3041 - val_loss: 0.2500\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.2540 - val_loss: 0.2586\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.2326 - val_loss: 0.2258\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.2219 - val_loss: 0.2299\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.2152 - val_loss: 0.2180\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 51ms/step - loss: 0.2097 - val_loss: 0.2118\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 51ms/step - loss: 0.2025 - val_loss: 0.2243\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.2100 - val_loss: 0.2071\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.2041 - val_loss: 0.2192\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1999 - val_loss: 0.2103\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.2031 - val_loss: 0.2140\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1967 - val_loss: 0.2143\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - loss: 0.2054 - val_loss: 0.2017\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.2006 - val_loss: 0.2051\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1999 - val_loss: 0.1979\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1948 - val_loss: 0.1948\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1902 - val_loss: 0.1969\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1956 - val_loss: 0.1924\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1897 - val_loss: 0.1970\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1882 - val_loss: 0.1934\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1906 - val_loss: 0.1968\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1864 - val_loss: 0.2017\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 51ms/step - loss: 0.1859 - val_loss: 0.2055\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - loss: 0.1856 - val_loss: 0.2265\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1943 - val_loss: 0.1919\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1889 - val_loss: 0.1843\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1802 - val_loss: 0.1841\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1769 - val_loss: 0.1825\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 51ms/step - loss: 0.1847 - val_loss: 0.1944\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 51ms/step - loss: 0.1813 - val_loss: 0.1856\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1828 - val_loss: 0.1778\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1718 - val_loss: 0.1729\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1747 - val_loss: 0.1710\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1668 - val_loss: 0.1802\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 53ms/step - loss: 0.1796 - val_loss: 0.1748\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 51ms/step - loss: 0.1712 - val_loss: 0.1657\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1647 - val_loss: 0.1665\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1658 - val_loss: 0.1700\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1608 - val_loss: 0.1602\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1603 - val_loss: 0.1614\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1599 - val_loss: 0.1630\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1568 - val_loss: 0.1649\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1526 - val_loss: 0.1561\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1583 - val_loss: 0.1648\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1497 - val_loss: 0.1595\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 52ms/step - loss: 0.1594 - val_loss: 0.1640\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 51ms/step - loss: 0.1465 - val_loss: 0.1619\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1476 - val_loss: 0.1523\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1469 - val_loss: 0.1569\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 51ms/step - loss: 0.1505 - val_loss: 0.1503\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1364 - val_loss: 0.1521\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1467 - val_loss: 0.1554\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1380 - val_loss: 0.1499\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1452 - val_loss: 0.1579\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1466 - val_loss: 0.1539\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1387 - val_loss: 0.1480\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1383 - val_loss: 0.1499\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1373 - val_loss: 0.1459\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 51ms/step - loss: 0.1382 - val_loss: 0.1473\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1344 - val_loss: 0.1473\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1314 - val_loss: 0.1492\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1335 - val_loss: 0.1446\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 51ms/step - loss: 0.1335 - val_loss: 0.1479\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1310 - val_loss: 0.1510\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 51ms/step - loss: 0.1327 - val_loss: 0.1477\n",
      "Epoch 67/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1313 - val_loss: 0.1615\n",
      "Epoch 68/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 49ms/step - loss: 0.1319 - val_loss: 0.1454\n",
      "Epoch 69/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1281 - val_loss: 0.1467\n",
      "Epoch 70/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 53ms/step - loss: 0.1261 - val_loss: 0.1472\n",
      "Epoch 71/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 49ms/step - loss: 0.1281 - val_loss: 0.1459\n",
      "Epoch 72/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1283 - val_loss: 0.1518\n",
      "Epoch 73/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1246 - val_loss: 0.1508\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.1518\n",
      "Hidden Layers: 4, Neurons 96\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 69ms/step - loss: 0.9832 - val_loss: 0.4319\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.3374 - val_loss: 0.2934\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 67ms/step - loss: 0.2773 - val_loss: 0.2529\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.2523 - val_loss: 0.2621\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.2467 - val_loss: 0.2324\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.2375 - val_loss: 0.2261\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.2205 - val_loss: 0.2620\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 67ms/step - loss: 0.2186 - val_loss: 0.2190\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 70ms/step - loss: 0.2289 - val_loss: 0.2379\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.2260 - val_loss: 0.2260\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.2152 - val_loss: 0.2160\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.2100 - val_loss: 0.2042\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.2046 - val_loss: 0.2000\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.2099 - val_loss: 0.2045\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.2057 - val_loss: 0.2172\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1999 - val_loss: 0.1951\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 67ms/step - loss: 0.2077 - val_loss: 0.2731\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 67ms/step - loss: 0.2409 - val_loss: 0.2030\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1964 - val_loss: 0.1980\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1992 - val_loss: 0.1987\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 70ms/step - loss: 0.1918 - val_loss: 0.1915\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1900 - val_loss: 0.1881\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 67ms/step - loss: 0.1895 - val_loss: 0.1881\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1831 - val_loss: 0.1853\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.2012 - val_loss: 0.1868\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 70ms/step - loss: 0.1793 - val_loss: 0.1802\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1747 - val_loss: 0.1730\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 67ms/step - loss: 0.1778 - val_loss: 0.1785\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1715 - val_loss: 0.1834\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 71ms/step - loss: 0.1731 - val_loss: 0.1730\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1804 - val_loss: 0.1823\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1927 - val_loss: 0.1842\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1746 - val_loss: 0.1720\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 70ms/step - loss: 0.1727 - val_loss: 0.1774\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1666 - val_loss: 0.1658\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1665 - val_loss: 0.1744\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1681 - val_loss: 0.1650\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1685 - val_loss: 0.1951\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 67ms/step - loss: 0.1769 - val_loss: 0.1621\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1762 - val_loss: 0.1642\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1563 - val_loss: 0.1630\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1576 - val_loss: 0.1824\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1679 - val_loss: 0.1792\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1652 - val_loss: 0.1573\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1520 - val_loss: 0.1582\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 71ms/step - loss: 0.1520 - val_loss: 0.1570\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1504 - val_loss: 0.1481\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1450 - val_loss: 0.1530\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 67ms/step - loss: 0.1458 - val_loss: 0.1649\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1538 - val_loss: 0.2233\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1647 - val_loss: 0.1572\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1485 - val_loss: 0.1562\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1476 - val_loss: 0.1515\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 67ms/step - loss: 0.1384 - val_loss: 0.1453\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1363 - val_loss: 0.1471\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1416 - val_loss: 0.1500\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1445 - val_loss: 0.1472\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1387 - val_loss: 0.1488\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 67ms/step - loss: 0.1353 - val_loss: 0.1508\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1383 - val_loss: 0.1536\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1591 - val_loss: 0.1929\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1698 - val_loss: 0.1503\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 70ms/step - loss: 0.1381 - val_loss: 0.1503\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 71ms/step - loss: 0.1414 - val_loss: 0.1478\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.1484\n",
      "Hidden Layers: 4, Neurons 128\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 89ms/step - loss: 0.9331 - val_loss: 0.3061\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.2849 - val_loss: 0.2807\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.2451 - val_loss: 0.2367\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.2367 - val_loss: 0.2299\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.2281 - val_loss: 0.2128\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.2362 - val_loss: 0.2172\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 89ms/step - loss: 0.2204 - val_loss: 0.2124\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.2200 - val_loss: 0.2074\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - loss: 0.2067 - val_loss: 0.2149\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.2092 - val_loss: 0.2183\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.2022 - val_loss: 0.1999\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1933 - val_loss: 0.2017\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.1924 - val_loss: 0.2011\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.2065 - val_loss: 0.2499\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.2055 - val_loss: 0.2005\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1897 - val_loss: 0.2065\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.1910 - val_loss: 0.1858\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 85ms/step - loss: 0.2032 - val_loss: 0.1979\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1924 - val_loss: 0.1874\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.1819 - val_loss: 0.1986\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.1893 - val_loss: 0.1810\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.1767 - val_loss: 0.1741\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.1781 - val_loss: 0.1832\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1756 - val_loss: 0.1825\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1732 - val_loss: 0.1663\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.1823 - val_loss: 0.1726\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.1675 - val_loss: 0.1744\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.1671 - val_loss: 0.1654\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - loss: 0.1606 - val_loss: 0.1573\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - loss: 0.1605 - val_loss: 0.1572\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1579 - val_loss: 0.1654\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.1550 - val_loss: 0.1545\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1513 - val_loss: 0.1671\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.1674 - val_loss: 0.1548\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1574 - val_loss: 0.1550\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1520 - val_loss: 0.1566\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1494 - val_loss: 0.1508\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1465 - val_loss: 0.1510\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.1388 - val_loss: 0.1468\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 85ms/step - loss: 0.1450 - val_loss: 0.1519\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1385 - val_loss: 0.1517\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - loss: 0.1395 - val_loss: 0.1512\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1379 - val_loss: 0.1498\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - loss: 0.1336 - val_loss: 0.1479\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.1410 - val_loss: 0.1469\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1317 - val_loss: 0.1470\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1391 - val_loss: 0.1459\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.1362 - val_loss: 0.1473\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.1355 - val_loss: 0.1576\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.1351 - val_loss: 0.1455\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1294 - val_loss: 0.1470\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.1274 - val_loss: 0.1468\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.1328 - val_loss: 0.1480\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1267 - val_loss: 0.1456\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1279 - val_loss: 0.1465\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1186 - val_loss: 0.1526\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - loss: 0.1267 - val_loss: 0.1510\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.1199 - val_loss: 0.1528\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 85ms/step - loss: 0.1193 - val_loss: 0.1489\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - loss: 0.1220 - val_loss: 0.1505\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.1522\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = 4\n",
    "neurons = [16, 32, 64, 96, 128]\n",
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "for n in neurons:\n",
    "    print(f\"Hidden Layers: {hidden_layers}, Neurons {n}\"), \n",
    "    regressor, mse = initModel(hidden_layers, n, epochs, batch_size)\n",
    "    results.append({'MSE': mse, 'Hidden Layers': hidden_layers, 'Neurons': n, 'Model': regressor})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Neurons</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141757</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;Sequential name=sequential_3, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.141924</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;Sequential name=sequential_8, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.142399</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_12, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.143165</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;Sequential name=sequential_14, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144534</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;Sequential name=sequential_4, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.144564</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_17, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.144724</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;Sequential name=sequential_9, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.145036</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_2, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.145313</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;Sequential name=sequential_18, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.145463</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;Sequential name=sequential_19, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.145470</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;Sequential name=sequential_13, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.147063</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_1, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.148014</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_7, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.148603</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_11, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.149235</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_16, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.151017</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_15, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.153365</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_6, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.168463</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.169782</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_10, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.182994</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_5, built=True&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MSE  Hidden Layers  Neurons  \\\n",
       "3   0.141757              1       96   \n",
       "8   0.141924              2       96   \n",
       "12  0.142399              3       64   \n",
       "14  0.143165              3      128   \n",
       "4   0.144534              1      128   \n",
       "17  0.144564              4       64   \n",
       "9   0.144724              2      128   \n",
       "2   0.145036              1       64   \n",
       "18  0.145313              4       96   \n",
       "19  0.145463              4      128   \n",
       "13  0.145470              3       96   \n",
       "1   0.147063              1       32   \n",
       "7   0.148014              2       64   \n",
       "11  0.148603              3       32   \n",
       "16  0.149235              4       32   \n",
       "15  0.151017              4       16   \n",
       "6   0.153365              2       32   \n",
       "0   0.168463              1       16   \n",
       "10  0.169782              3       16   \n",
       "5   0.182994              2       16   \n",
       "\n",
       "                                          Model  \n",
       "3    <Sequential name=sequential_3, built=True>  \n",
       "8    <Sequential name=sequential_8, built=True>  \n",
       "12  <Sequential name=sequential_12, built=True>  \n",
       "14  <Sequential name=sequential_14, built=True>  \n",
       "4    <Sequential name=sequential_4, built=True>  \n",
       "17  <Sequential name=sequential_17, built=True>  \n",
       "9    <Sequential name=sequential_9, built=True>  \n",
       "2    <Sequential name=sequential_2, built=True>  \n",
       "18  <Sequential name=sequential_18, built=True>  \n",
       "19  <Sequential name=sequential_19, built=True>  \n",
       "13  <Sequential name=sequential_13, built=True>  \n",
       "1    <Sequential name=sequential_1, built=True>  \n",
       "7    <Sequential name=sequential_7, built=True>  \n",
       "11  <Sequential name=sequential_11, built=True>  \n",
       "16  <Sequential name=sequential_16, built=True>  \n",
       "15  <Sequential name=sequential_15, built=True>  \n",
       "6    <Sequential name=sequential_6, built=True>  \n",
       "0      <Sequential name=sequential, built=True>  \n",
       "10  <Sequential name=sequential_10, built=True>  \n",
       "5    <Sequential name=sequential_5, built=True>  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "df_results.sort_values(by='MSE').head(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layers: 1, Neurons 80\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 1.2852 - val_loss: 0.4719\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - loss: 0.4838 - val_loss: 0.4201\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.4066 - val_loss: 0.3315\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.3319 - val_loss: 0.2950\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2936 - val_loss: 0.2908\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.2864 - val_loss: 0.2925\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2888 - val_loss: 0.2603\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2625 - val_loss: 0.2522\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.2463 - val_loss: 0.2587\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.2462 - val_loss: 0.2557\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2464 - val_loss: 0.2461\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.2339 - val_loss: 0.2295\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.2246 - val_loss: 0.2259\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2253 - val_loss: 0.2329\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.2166 - val_loss: 0.2303\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2079 - val_loss: 0.2101\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2111 - val_loss: 0.2053\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.2085 - val_loss: 0.2071\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2048 - val_loss: 0.2086\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1996 - val_loss: 0.2342\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2001 - val_loss: 0.1930\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2022 - val_loss: 0.2025\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1979 - val_loss: 0.2029\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1959 - val_loss: 0.1940\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1910 - val_loss: 0.1952\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1930 - val_loss: 0.1895\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1922 - val_loss: 0.1871\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1841 - val_loss: 0.1875\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1867 - val_loss: 0.1915\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1896 - val_loss: 0.1855\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1788 - val_loss: 0.1851\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1872 - val_loss: 0.1821\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1844 - val_loss: 0.1765\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1786 - val_loss: 0.1762\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1802 - val_loss: 0.1763\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1752 - val_loss: 0.1717\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1769 - val_loss: 0.1690\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1664 - val_loss: 0.1659\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1714 - val_loss: 0.1689\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1670 - val_loss: 0.1685\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1672 - val_loss: 0.1636\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1633 - val_loss: 0.1624\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1587 - val_loss: 0.1664\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1623 - val_loss: 0.1582\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1633 - val_loss: 0.1599\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1508 - val_loss: 0.1623\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1586 - val_loss: 0.1529\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1537 - val_loss: 0.1588\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1534 - val_loss: 0.1567\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1439 - val_loss: 0.1581\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1468 - val_loss: 0.1595\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1519 - val_loss: 0.1534\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1446 - val_loss: 0.1503\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1461 - val_loss: 0.1507\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1424 - val_loss: 0.1553\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1444 - val_loss: 0.1566\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1421 - val_loss: 0.1622\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1400 - val_loss: 0.1473\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1425 - val_loss: 0.1465\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - loss: 0.1410 - val_loss: 0.1496\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - loss: 0.1432 - val_loss: 0.1531\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 55ms/step - loss: 0.1389 - val_loss: 0.1483\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - loss: 0.1432 - val_loss: 0.1476\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - loss: 0.1392 - val_loss: 0.1468\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 50ms/step - loss: 0.1389 - val_loss: 0.1481\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 55ms/step - loss: 0.1386 - val_loss: 0.1447\n",
      "Epoch 67/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 55ms/step - loss: 0.1353 - val_loss: 0.1465\n",
      "Epoch 68/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - loss: 0.1320 - val_loss: 0.1481\n",
      "Epoch 69/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - loss: 0.1366 - val_loss: 0.1517\n",
      "Epoch 70/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - loss: 0.1352 - val_loss: 0.1469\n",
      "Epoch 71/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 57ms/step - loss: 0.1325 - val_loss: 0.1500\n",
      "Epoch 72/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 61ms/step - loss: 0.1362 - val_loss: 0.1461\n",
      "Epoch 73/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 60ms/step - loss: 0.1349 - val_loss: 0.1453\n",
      "Epoch 74/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 56ms/step - loss: 0.1370 - val_loss: 0.1470\n",
      "Epoch 75/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - loss: 0.1344 - val_loss: 0.1450\n",
      "Epoch 76/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 36ms/step - loss: 0.1318 - val_loss: 0.1462\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1509\n",
      "Hidden Layers: 2, Neurons 80\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - loss: 1.0055 - val_loss: 0.2978\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.2987 - val_loss: 0.2422\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.2486 - val_loss: 0.2466\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.2404 - val_loss: 0.2336\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.2251 - val_loss: 0.3021\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.2461 - val_loss: 0.2509\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 102ms/step - loss: 0.2212 - val_loss: 0.2229\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.2149 - val_loss: 0.2416\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2125 - val_loss: 0.2261\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - loss: 0.2111 - val_loss: 0.2272\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 39ms/step - loss: 0.2029 - val_loss: 0.2143\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 38ms/step - loss: 0.2137 - val_loss: 0.2037\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - loss: 0.2030 - val_loss: 0.2097\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.2033 - val_loss: 0.2367\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 54ms/step - loss: 0.2059 - val_loss: 0.1993\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - loss: 0.2026 - val_loss: 0.2006\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.2062 - val_loss: 0.1986\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.2062 - val_loss: 0.1977\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1946 - val_loss: 0.1979\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1886 - val_loss: 0.1913\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1890 - val_loss: 0.1942\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1909 - val_loss: 0.1879\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1915 - val_loss: 0.2052\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1854 - val_loss: 0.2035\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 34ms/step - loss: 0.1908 - val_loss: 0.2033\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1859 - val_loss: 0.1895\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1836 - val_loss: 0.1866\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1866 - val_loss: 0.1892\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1796 - val_loss: 0.1746\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1775 - val_loss: 0.1712\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1687 - val_loss: 0.1761\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1694 - val_loss: 0.1678\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 41ms/step - loss: 0.1774 - val_loss: 0.1752\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 111ms/step - loss: 0.1677 - val_loss: 0.1667\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 110ms/step - loss: 0.1671 - val_loss: 0.1724\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 116ms/step - loss: 0.1680 - val_loss: 0.1647\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 113ms/step - loss: 0.1564 - val_loss: 0.1632\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 112ms/step - loss: 0.1617 - val_loss: 0.1616\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 112ms/step - loss: 0.1609 - val_loss: 0.1662\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 79ms/step - loss: 0.1625 - val_loss: 0.1679\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 65ms/step - loss: 0.1605 - val_loss: 0.1660\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 0.1486 - val_loss: 0.1709\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.1567 - val_loss: 0.1611\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 54ms/step - loss: 0.1533 - val_loss: 0.1552\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 55ms/step - loss: 0.1487 - val_loss: 0.1582\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 65ms/step - loss: 0.1472 - val_loss: 0.1529\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 85ms/step - loss: 0.1413 - val_loss: 0.1554\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 55ms/step - loss: 0.1442 - val_loss: 0.1619\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 53ms/step - loss: 0.1464 - val_loss: 0.1536\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 53ms/step - loss: 0.1511 - val_loss: 0.1554\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 53ms/step - loss: 0.1432 - val_loss: 0.1451\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 53ms/step - loss: 0.1460 - val_loss: 0.1472\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 53ms/step - loss: 0.1384 - val_loss: 0.1488\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 54ms/step - loss: 0.1421 - val_loss: 0.1576\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 54ms/step - loss: 0.1415 - val_loss: 0.1505\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 53ms/step - loss: 0.1397 - val_loss: 0.1465\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 53ms/step - loss: 0.1342 - val_loss: 0.1482\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 54ms/step - loss: 0.1402 - val_loss: 0.1583\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 54ms/step - loss: 0.1353 - val_loss: 0.1537\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 54ms/step - loss: 0.1338 - val_loss: 0.1504\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 55ms/step - loss: 0.1422 - val_loss: 0.1480\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.1500\n",
      "Hidden Layers: 3, Neurons 80\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 85ms/step - loss: 0.9856 - val_loss: 0.2745\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.2723 - val_loss: 0.2468\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.2566 - val_loss: 0.2346\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.2439 - val_loss: 0.2273\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - loss: 0.2385 - val_loss: 0.2149\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.2281 - val_loss: 0.2402\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.2227 - val_loss: 0.2080\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.2072 - val_loss: 0.2171\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.2243 - val_loss: 0.2115\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.2073 - val_loss: 0.2157\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.2144 - val_loss: 0.2054\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.2037 - val_loss: 0.1984\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.2138 - val_loss: 0.2058\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1938 - val_loss: 0.2044\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.1923 - val_loss: 0.1979\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.2030 - val_loss: 0.1968\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 83ms/step - loss: 0.1944 - val_loss: 0.1956\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.1984 - val_loss: 0.1978\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 83ms/step - loss: 0.1963 - val_loss: 0.1901\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1896 - val_loss: 0.1895\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.1916 - val_loss: 0.1928\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.1945 - val_loss: 0.1890\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1988 - val_loss: 0.1907\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - loss: 0.1891 - val_loss: 0.1829\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1877 - val_loss: 0.1917\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.1805 - val_loss: 0.1832\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1778 - val_loss: 0.1867\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1807 - val_loss: 0.1747\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 83ms/step - loss: 0.1760 - val_loss: 0.1717\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.1751 - val_loss: 0.1734\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.1701 - val_loss: 0.1690\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - loss: 0.1696 - val_loss: 0.1765\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1655 - val_loss: 0.1646\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 82ms/step - loss: 0.1678 - val_loss: 0.1695\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1613 - val_loss: 0.1686\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.1624 - val_loss: 0.1635\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1557 - val_loss: 0.1606\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 82ms/step - loss: 0.1554 - val_loss: 0.1619\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.1614 - val_loss: 0.1581\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1583 - val_loss: 0.1590\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1517 - val_loss: 0.1639\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1468 - val_loss: 0.1580\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1478 - val_loss: 0.1566\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1458 - val_loss: 0.1525\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.1469 - val_loss: 0.1573\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1494 - val_loss: 0.1530\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.1429 - val_loss: 0.1518\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1479 - val_loss: 0.1548\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.1462 - val_loss: 0.1581\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 82ms/step - loss: 0.1445 - val_loss: 0.1508\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.1429 - val_loss: 0.1505\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1441 - val_loss: 0.1564\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1397 - val_loss: 0.1562\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1425 - val_loss: 0.1480\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1378 - val_loss: 0.1499\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.1407 - val_loss: 0.1475\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 82ms/step - loss: 0.1407 - val_loss: 0.1521\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 83ms/step - loss: 0.1329 - val_loss: 0.1520\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1363 - val_loss: 0.1499\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1345 - val_loss: 0.1523\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 83ms/step - loss: 0.1344 - val_loss: 0.1490\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1397 - val_loss: 0.1494\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.1362 - val_loss: 0.1507\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1302 - val_loss: 0.1505\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 82ms/step - loss: 0.1299 - val_loss: 0.1501\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.1276 - val_loss: 0.1506\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.1509\n",
      "Hidden Layers: 4, Neurons 80\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 108ms/step - loss: 0.9128 - val_loss: 0.4866\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 106ms/step - loss: 0.3512 - val_loss: 0.2739\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 103ms/step - loss: 0.2728 - val_loss: 0.2655\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.2494 - val_loss: 0.2570\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.2577 - val_loss: 0.2346\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.2348 - val_loss: 0.2274\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 103ms/step - loss: 0.2332 - val_loss: 0.2291\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 103ms/step - loss: 0.2259 - val_loss: 0.2547\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.2180 - val_loss: 0.2118\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.2203 - val_loss: 0.2231\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.2257 - val_loss: 0.2138\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.2046 - val_loss: 0.2007\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.2006 - val_loss: 0.2542\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.2095 - val_loss: 0.2091\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.1992 - val_loss: 0.2044\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 103ms/step - loss: 0.1954 - val_loss: 0.1962\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.1953 - val_loss: 0.1961\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.1951 - val_loss: 0.2090\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.1915 - val_loss: 0.1923\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.1922 - val_loss: 0.1932\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.1855 - val_loss: 0.1955\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.1763 - val_loss: 0.1902\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 106ms/step - loss: 0.2004 - val_loss: 0.1953\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.1912 - val_loss: 0.1954\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.1876 - val_loss: 0.1856\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.1814 - val_loss: 0.1869\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.1917 - val_loss: 0.1780\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 106ms/step - loss: 0.1752 - val_loss: 0.1808\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.1872 - val_loss: 0.1768\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.1753 - val_loss: 0.1770\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.1775 - val_loss: 0.1745\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.1819 - val_loss: 0.1724\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.1720 - val_loss: 0.1751\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.1632 - val_loss: 0.1698\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 107ms/step - loss: 0.1684 - val_loss: 0.1708\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 106ms/step - loss: 0.1633 - val_loss: 0.1668\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.1624 - val_loss: 0.1676\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.1660 - val_loss: 0.1613\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.1590 - val_loss: 0.1601\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.1568 - val_loss: 0.1672\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.1531 - val_loss: 0.1567\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 107ms/step - loss: 0.1463 - val_loss: 0.1624\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.1581 - val_loss: 0.1574\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.1501 - val_loss: 0.1519\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.1543 - val_loss: 0.1624\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 106ms/step - loss: 0.1421 - val_loss: 0.1517\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 0.1414 - val_loss: 0.1511\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 111ms/step - loss: 0.1388 - val_loss: 0.1547\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 106ms/step - loss: 0.1445 - val_loss: 0.1583\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 106ms/step - loss: 0.1435 - val_loss: 0.1471\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 107ms/step - loss: 0.1344 - val_loss: 0.1619\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 0.1445 - val_loss: 0.1515\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 103ms/step - loss: 0.1350 - val_loss: 0.1494\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 69ms/step - loss: 0.1358 - val_loss: 0.1453\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 52ms/step - loss: 0.1346 - val_loss: 0.1485\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 54ms/step - loss: 0.1308 - val_loss: 0.1446\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 54ms/step - loss: 0.1329 - val_loss: 0.1477\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 53ms/step - loss: 0.1304 - val_loss: 0.1520\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 53ms/step - loss: 0.1288 - val_loss: 0.1528\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 53ms/step - loss: 0.1296 - val_loss: 0.1498\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 53ms/step - loss: 0.1309 - val_loss: 0.1543\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 52ms/step - loss: 0.1300 - val_loss: 0.1497\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 52ms/step - loss: 0.1216 - val_loss: 0.1506\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 54ms/step - loss: 0.1214 - val_loss: 0.1558\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 54ms/step - loss: 0.1339 - val_loss: 0.1492\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 55ms/step - loss: 0.1216 - val_loss: 0.1497\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1483\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = [1, 2, 3, 4]\n",
    "neurons = 160\n",
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "for h in hidden_layers:\n",
    "    print(f\"Hidden Layers: {h}, Neurons {n}\"), \n",
    "    regressor, mse = initModel(h, n, epochs, batch_size)\n",
    "    results.append({'MSE': mse, 'Hidden Layers': h, 'Neurons': neurons, 'Model': regressor})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Neurons</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141757</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;Sequential name=sequential_3, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.141924</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;Sequential name=sequential_8, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.142399</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_12, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.143165</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;Sequential name=sequential_14, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144534</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;Sequential name=sequential_4, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.144564</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_17, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.144629</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>&lt;Sequential name=sequential_39, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.144708</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>&lt;Sequential name=sequential_36, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.144724</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;Sequential name=sequential_9, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.145036</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_2, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.145091</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>&lt;Sequential name=sequential_37, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.145313</td>\n",
       "      <td>4</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;Sequential name=sequential_18, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.145463</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>&lt;Sequential name=sequential_19, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.145470</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>&lt;Sequential name=sequential_13, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.147063</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_1, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.147506</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>&lt;Sequential name=sequential_38, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.148014</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_7, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.148603</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_11, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.149235</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_16, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.151017</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_15, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.153365</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_6, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.168463</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.169782</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_10, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.182994</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_5, built=True&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MSE  Hidden Layers  Neurons  \\\n",
       "3   0.141757              1       96   \n",
       "8   0.141924              2       96   \n",
       "12  0.142399              3       64   \n",
       "14  0.143165              3      128   \n",
       "4   0.144534              1      128   \n",
       "17  0.144564              4       64   \n",
       "23  0.144629              4      160   \n",
       "20  0.144708              1      160   \n",
       "9   0.144724              2      128   \n",
       "2   0.145036              1       64   \n",
       "21  0.145091              2      160   \n",
       "18  0.145313              4       96   \n",
       "19  0.145463              4      128   \n",
       "13  0.145470              3       96   \n",
       "1   0.147063              1       32   \n",
       "22  0.147506              3      160   \n",
       "7   0.148014              2       64   \n",
       "11  0.148603              3       32   \n",
       "16  0.149235              4       32   \n",
       "15  0.151017              4       16   \n",
       "6   0.153365              2       32   \n",
       "0   0.168463              1       16   \n",
       "10  0.169782              3       16   \n",
       "5   0.182994              2       16   \n",
       "\n",
       "                                          Model  \n",
       "3    <Sequential name=sequential_3, built=True>  \n",
       "8    <Sequential name=sequential_8, built=True>  \n",
       "12  <Sequential name=sequential_12, built=True>  \n",
       "14  <Sequential name=sequential_14, built=True>  \n",
       "4    <Sequential name=sequential_4, built=True>  \n",
       "17  <Sequential name=sequential_17, built=True>  \n",
       "23  <Sequential name=sequential_39, built=True>  \n",
       "20  <Sequential name=sequential_36, built=True>  \n",
       "9    <Sequential name=sequential_9, built=True>  \n",
       "2    <Sequential name=sequential_2, built=True>  \n",
       "21  <Sequential name=sequential_37, built=True>  \n",
       "18  <Sequential name=sequential_18, built=True>  \n",
       "19  <Sequential name=sequential_19, built=True>  \n",
       "13  <Sequential name=sequential_13, built=True>  \n",
       "1    <Sequential name=sequential_1, built=True>  \n",
       "22  <Sequential name=sequential_38, built=True>  \n",
       "7    <Sequential name=sequential_7, built=True>  \n",
       "11  <Sequential name=sequential_11, built=True>  \n",
       "16  <Sequential name=sequential_16, built=True>  \n",
       "15  <Sequential name=sequential_15, built=True>  \n",
       "6    <Sequential name=sequential_6, built=True>  \n",
       "0      <Sequential name=sequential, built=True>  \n",
       "10  <Sequential name=sequential_10, built=True>  \n",
       "5    <Sequential name=sequential_5, built=True>  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "df_results.sort_values(by='MSE').head(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in results:\n",
    "    row['Model'].save(str(row['Neurons']) + '_neurons_' + str(row['Hidden Layers']) + '_layers_' + '.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter DataFrame for each hidden layer and plot\n",
    "hidden_layers = df_results['Hidden Layers'].unique()\n",
    "for layer in hidden_layers:\n",
    "    df_layer = df_results[df_results['Hidden Layers'] == layer]\n",
    "    plt.plot(df_layer['Neurons'], df_layer['MSE'], label=f'{layer} Hidden Layer(s)')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Number of Neurons')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "# plt.title('MSE vs Neurons for Each Hidden Layer')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(range(int(df_results['Neurons'].min()), int(df_results['Neurons'].max())+1, 16), rotation=45)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 10\n",
      "Epoch 1/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 0.7766 - val_loss: 0.4771\n",
      "Epoch 2/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.4414 - val_loss: 0.4771\n",
      "Epoch 3/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.4623 - val_loss: 0.4571\n",
      "Epoch 4/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.4461 - val_loss: 0.3799\n",
      "Epoch 5/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.4279 - val_loss: 0.3823\n",
      "Epoch 6/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.3093 - val_loss: 0.2676\n",
      "Epoch 7/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - loss: 0.2693 - val_loss: 0.2667\n",
      "Epoch 8/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.2679 - val_loss: 0.2536\n",
      "Epoch 9/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.2523 - val_loss: 0.2538\n",
      "Epoch 10/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.2431 - val_loss: 0.2394\n",
      "Epoch 11/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 0.2396 - val_loss: 0.2200\n",
      "Epoch 12/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.2130 - val_loss: 0.1917\n",
      "Epoch 13/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1981 - val_loss: 0.1887\n",
      "Epoch 14/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1848 - val_loss: 0.1724\n",
      "Epoch 15/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1835 - val_loss: 0.1714\n",
      "Epoch 16/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1757 - val_loss: 0.1721\n",
      "Epoch 17/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1723 - val_loss: 0.1660\n",
      "Epoch 18/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1719 - val_loss: 0.1599\n",
      "Epoch 19/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1725 - val_loss: 0.1613\n",
      "Epoch 20/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1682 - val_loss: 0.1569\n",
      "Epoch 21/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1614 - val_loss: 0.1579\n",
      "Epoch 22/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1648 - val_loss: 0.1541\n",
      "Epoch 23/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1567 - val_loss: 0.1556\n",
      "Epoch 24/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1518 - val_loss: 0.1553\n",
      "Epoch 25/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1526 - val_loss: 0.1467\n",
      "Epoch 26/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1480 - val_loss: 0.1483\n",
      "Epoch 27/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1441 - val_loss: 0.1486\n",
      "Epoch 28/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1453 - val_loss: 0.1538\n",
      "Epoch 29/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 0.1399 - val_loss: 0.1648\n",
      "Epoch 30/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1438 - val_loss: 0.1541\n",
      "Epoch 31/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1453 - val_loss: 0.4099\n",
      "Epoch 32/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1430 - val_loss: 0.1502\n",
      "Epoch 33/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1435 - val_loss: 0.1448\n",
      "Epoch 34/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1437 - val_loss: 0.1442\n",
      "Epoch 35/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1348 - val_loss: 0.1411\n",
      "Epoch 36/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1385 - val_loss: 0.1560\n",
      "Epoch 37/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1392 - val_loss: 0.1479\n",
      "Epoch 38/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1340 - val_loss: 0.1449\n",
      "Epoch 39/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1306 - val_loss: 0.1404\n",
      "Epoch 40/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1332 - val_loss: 0.1401\n",
      "Epoch 41/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1322 - val_loss: 0.1445\n",
      "Epoch 42/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1321 - val_loss: 0.1428\n",
      "Epoch 43/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1307 - val_loss: 0.1474\n",
      "Epoch 44/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1316 - val_loss: 0.1436\n",
      "Epoch 45/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1347 - val_loss: 0.1658\n",
      "Epoch 46/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - loss: 0.1206 - val_loss: 0.1647\n",
      "Epoch 47/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1259 - val_loss: 0.1484\n",
      "Epoch 48/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1225 - val_loss: 0.1541\n",
      "Epoch 49/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1222 - val_loss: 0.1451\n",
      "Epoch 50/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 0.1182 - val_loss: 0.1473\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1462\n",
      "Batch size: 16\n",
      "Epoch 1/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 1.0237 - val_loss: 0.4653\n",
      "Epoch 2/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.4601 - val_loss: 0.3916\n",
      "Epoch 3/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.3449 - val_loss: 0.2700\n",
      "Epoch 4/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.2650 - val_loss: 0.2529\n",
      "Epoch 5/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.2397 - val_loss: 0.2402\n",
      "Epoch 6/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.2419 - val_loss: 0.2337\n",
      "Epoch 7/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.2255 - val_loss: 0.2348\n",
      "Epoch 8/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.2245 - val_loss: 0.2134\n",
      "Epoch 9/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.2346 - val_loss: 0.2157\n",
      "Epoch 10/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.2142 - val_loss: 0.2237\n",
      "Epoch 11/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.2093 - val_loss: 0.2066\n",
      "Epoch 12/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.2071 - val_loss: 0.2100\n",
      "Epoch 13/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1978 - val_loss: 0.2019\n",
      "Epoch 14/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1995 - val_loss: 0.2025\n",
      "Epoch 15/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1946 - val_loss: 0.1927\n",
      "Epoch 16/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1899 - val_loss: 0.1889\n",
      "Epoch 17/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1866 - val_loss: 0.1800\n",
      "Epoch 18/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1806 - val_loss: 0.1640\n",
      "Epoch 19/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1798 - val_loss: 0.1790\n",
      "Epoch 20/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1741 - val_loss: 0.1686\n",
      "Epoch 21/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1672 - val_loss: 0.1622\n",
      "Epoch 22/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1602 - val_loss: 0.1672\n",
      "Epoch 23/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1570 - val_loss: 0.1549\n",
      "Epoch 24/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1593 - val_loss: 0.1552\n",
      "Epoch 25/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1514 - val_loss: 0.1709\n",
      "Epoch 26/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1546 - val_loss: 0.1593\n",
      "Epoch 27/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1453 - val_loss: 0.1513\n",
      "Epoch 28/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 0.1492 - val_loss: 0.1573\n",
      "Epoch 29/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1469 - val_loss: 0.1557\n",
      "Epoch 30/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1431 - val_loss: 0.1557\n",
      "Epoch 31/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 0.1438 - val_loss: 0.1513\n",
      "Epoch 32/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1468 - val_loss: 0.1492\n",
      "Epoch 33/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1421 - val_loss: 0.1491\n",
      "Epoch 34/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1416 - val_loss: 0.1528\n",
      "Epoch 35/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1453 - val_loss: 0.1474\n",
      "Epoch 36/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1412 - val_loss: 0.1467\n",
      "Epoch 37/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1384 - val_loss: 0.1459\n",
      "Epoch 38/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1337 - val_loss: 0.1463\n",
      "Epoch 39/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1357 - val_loss: 0.1463\n",
      "Epoch 40/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1346 - val_loss: 0.1455\n",
      "Epoch 41/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1349 - val_loss: 0.1434\n",
      "Epoch 42/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1286 - val_loss: 0.1465\n",
      "Epoch 43/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1354 - val_loss: 0.1426\n",
      "Epoch 44/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1387 - val_loss: 0.1454\n",
      "Epoch 45/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1291 - val_loss: 0.1442\n",
      "Epoch 46/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1353 - val_loss: 0.1521\n",
      "Epoch 47/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1337 - val_loss: 0.1482\n",
      "Epoch 48/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1301 - val_loss: 0.1430\n",
      "Epoch 49/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1324 - val_loss: 0.1448\n",
      "Epoch 50/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1297 - val_loss: 0.1445\n",
      "Epoch 51/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1288 - val_loss: 0.1457\n",
      "Epoch 52/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1299 - val_loss: 0.1433\n",
      "Epoch 53/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 0.1247 - val_loss: 0.1440\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1496\n",
      "Batch size: 32\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 1.1167 - val_loss: 0.5154\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.5202 - val_loss: 0.4536\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.4517 - val_loss: 0.3408\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.3255 - val_loss: 0.2788\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.2742 - val_loss: 0.2703\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2434 - val_loss: 0.2703\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2392 - val_loss: 0.2484\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2308 - val_loss: 0.2213\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2185 - val_loss: 0.2546\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2338 - val_loss: 0.2202\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2176 - val_loss: 0.2058\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2110 - val_loss: 0.2113\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2024 - val_loss: 0.2116\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2011 - val_loss: 0.2117\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2113 - val_loss: 0.2223\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.2038 - val_loss: 0.2463\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.2118 - val_loss: 0.2058\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1993 - val_loss: 0.1973\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1947 - val_loss: 0.1939\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1946 - val_loss: 0.1989\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1864 - val_loss: 0.1842\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1935 - val_loss: 0.1817\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1838 - val_loss: 0.2086\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1868 - val_loss: 0.1806\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1809 - val_loss: 0.1816\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1775 - val_loss: 0.1687\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1754 - val_loss: 0.1785\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1707 - val_loss: 0.1822\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1726 - val_loss: 0.1746\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1647 - val_loss: 0.1696\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1754 - val_loss: 0.1724\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1713 - val_loss: 0.1737\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1694 - val_loss: 0.1694\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1585 - val_loss: 0.1577\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1581 - val_loss: 0.1578\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1528 - val_loss: 0.1582\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1618 - val_loss: 0.1560\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1529 - val_loss: 0.1528\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1507 - val_loss: 0.1574\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1515 - val_loss: 0.1558\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1450 - val_loss: 0.1712\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1446 - val_loss: 0.1485\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1457 - val_loss: 0.1501\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1395 - val_loss: 0.1549\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1450 - val_loss: 0.1483\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1391 - val_loss: 0.1452\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1396 - val_loss: 0.1443\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1393 - val_loss: 0.1455\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1401 - val_loss: 0.1456\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1415 - val_loss: 0.1464\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1397 - val_loss: 0.1483\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - loss: 0.1401 - val_loss: 0.1517\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1366 - val_loss: 0.1453\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1304 - val_loss: 0.1471\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1342 - val_loss: 0.1464\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1339 - val_loss: 0.1432\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1354 - val_loss: 0.1452\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1344 - val_loss: 0.1585\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1329 - val_loss: 0.1475\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1320 - val_loss: 0.1443\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1332 - val_loss: 0.1543\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1254 - val_loss: 0.1477\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1290 - val_loss: 0.1554\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - loss: 0.1278 - val_loss: 0.1483\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1260 - val_loss: 0.1460\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - loss: 0.1269 - val_loss: 0.1468\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1493\n",
      "Batch size: 64\n",
      "Epoch 1/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 1.4098 - val_loss: 0.5069\n",
      "Epoch 2/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.5151 - val_loss: 0.4175\n",
      "Epoch 3/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.3834 - val_loss: 0.2872\n",
      "Epoch 4/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.2896 - val_loss: 0.2581\n",
      "Epoch 5/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.2566 - val_loss: 0.2526\n",
      "Epoch 6/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.2472 - val_loss: 0.2573\n",
      "Epoch 7/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.2286 - val_loss: 0.2300\n",
      "Epoch 8/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.2409 - val_loss: 0.2375\n",
      "Epoch 9/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.2327 - val_loss: 0.2323\n",
      "Epoch 10/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.2327 - val_loss: 0.2221\n",
      "Epoch 11/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.2276 - val_loss: 0.2177\n",
      "Epoch 12/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.2220 - val_loss: 0.2251\n",
      "Epoch 13/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.2226 - val_loss: 0.2191\n",
      "Epoch 14/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.2122 - val_loss: 0.2174\n",
      "Epoch 15/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.2114 - val_loss: 0.2163\n",
      "Epoch 16/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.2112 - val_loss: 0.2126\n",
      "Epoch 17/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.2177 - val_loss: 0.2163\n",
      "Epoch 18/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.2087 - val_loss: 0.2128\n",
      "Epoch 19/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.2156 - val_loss: 0.2358\n",
      "Epoch 20/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.2021 - val_loss: 0.2009\n",
      "Epoch 21/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1974 - val_loss: 0.2141\n",
      "Epoch 22/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.2005 - val_loss: 0.1969\n",
      "Epoch 23/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.2013 - val_loss: 0.1949\n",
      "Epoch 24/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1929 - val_loss: 0.1994\n",
      "Epoch 25/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1973 - val_loss: 0.1944\n",
      "Epoch 26/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 0.1896 - val_loss: 0.2124\n",
      "Epoch 27/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.2063 - val_loss: 0.1954\n",
      "Epoch 28/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1904 - val_loss: 0.1987\n",
      "Epoch 29/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1973 - val_loss: 0.1949\n",
      "Epoch 30/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1938 - val_loss: 0.1888\n",
      "Epoch 31/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1942 - val_loss: 0.1939\n",
      "Epoch 32/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1943 - val_loss: 0.1912\n",
      "Epoch 33/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1897 - val_loss: 0.1860\n",
      "Epoch 34/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1870 - val_loss: 0.2060\n",
      "Epoch 35/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1986 - val_loss: 0.1916\n",
      "Epoch 36/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1874 - val_loss: 0.1859\n",
      "Epoch 37/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1860 - val_loss: 0.1873\n",
      "Epoch 38/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1810 - val_loss: 0.1836\n",
      "Epoch 39/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1875 - val_loss: 0.1902\n",
      "Epoch 40/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1822 - val_loss: 0.1874\n",
      "Epoch 41/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1874 - val_loss: 0.1806\n",
      "Epoch 42/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1878 - val_loss: 0.1899\n",
      "Epoch 43/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1740 - val_loss: 0.1731\n",
      "Epoch 44/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1794 - val_loss: 0.1767\n",
      "Epoch 45/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1703 - val_loss: 0.1725\n",
      "Epoch 46/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1778 - val_loss: 0.1873\n",
      "Epoch 47/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1873 - val_loss: 0.1711\n",
      "Epoch 48/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1788 - val_loss: 0.1726\n",
      "Epoch 49/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1716 - val_loss: 0.1737\n",
      "Epoch 50/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1719 - val_loss: 0.1702\n",
      "Epoch 51/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1659 - val_loss: 0.1714\n",
      "Epoch 52/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1752 - val_loss: 0.1699\n",
      "Epoch 53/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1705 - val_loss: 0.1659\n",
      "Epoch 54/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1691 - val_loss: 0.1771\n",
      "Epoch 55/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1727 - val_loss: 0.1652\n",
      "Epoch 56/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1636 - val_loss: 0.1664\n",
      "Epoch 57/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1674 - val_loss: 0.1713\n",
      "Epoch 58/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1642 - val_loss: 0.1771\n",
      "Epoch 59/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1621 - val_loss: 0.1690\n",
      "Epoch 60/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1637 - val_loss: 0.1683\n",
      "Epoch 61/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.1543 - val_loss: 0.1667\n",
      "Epoch 62/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1696 - val_loss: 0.1664\n",
      "Epoch 63/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.1612 - val_loss: 0.1660\n",
      "Epoch 64/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1596 - val_loss: 0.1674\n",
      "Epoch 65/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 0.1578 - val_loss: 0.1660\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1708\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = 1\n",
    "neurons = 96\n",
    "epochs = 150\n",
    "batch_size = [10, 16, 32, 64]\n",
    "\n",
    "for b in batch_size:\n",
    "    print(f\"Batch size: {b}\"), \n",
    "    regressor, mse = initModel(hidden_layers, neurons, epochs, b)\n",
    "    batch_size_results.append({'MSE': mse, 'Hidden Layers': hidden_layers, 'Neurons': neurons, 'Batch Size' : b, 'Model': regressor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Neurons</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140007</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_31, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.140166</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;Sequential name=sequential_55, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142031</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;Sequential name=sequential_28, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.142381</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_53, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.142513</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;Sequential name=sequential_43, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.142859</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_56, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.143188</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_57, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.143350</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;Sequential name=sequential_51, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.144116</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_29, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.144212</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_30, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.144917</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_52, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.145264</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_45, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.145682</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_44, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.147124</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>&lt;Sequential name=sequential_32, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.148008</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_54, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.150377</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_46, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.165816</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_58, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.191249</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>&lt;Sequential name=sequential_47, built=True&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MSE  Hidden Layers  Neurons  Batch Size  \\\n",
       "3   0.140007              1       80          64   \n",
       "14  0.140166              1       96          10   \n",
       "0   0.142031              1       80          10   \n",
       "12  0.142381              1       80          32   \n",
       "5   0.142513              2       80          10   \n",
       "15  0.142859              1       96          16   \n",
       "16  0.143188              1       96          32   \n",
       "10  0.143350              1       80          10   \n",
       "1   0.144116              1       80          16   \n",
       "2   0.144212              1       80          32   \n",
       "11  0.144917              1       80          16   \n",
       "7   0.145264              2       80          32   \n",
       "6   0.145682              2       80          16   \n",
       "4   0.147124              1       80          80   \n",
       "13  0.148008              1       80          64   \n",
       "8   0.150377              2       80          64   \n",
       "17  0.165816              1       96          64   \n",
       "9   0.191249              2       80          80   \n",
       "\n",
       "                                          Model  \n",
       "3   <Sequential name=sequential_31, built=True>  \n",
       "14  <Sequential name=sequential_55, built=True>  \n",
       "0   <Sequential name=sequential_28, built=True>  \n",
       "12  <Sequential name=sequential_53, built=True>  \n",
       "5   <Sequential name=sequential_43, built=True>  \n",
       "15  <Sequential name=sequential_56, built=True>  \n",
       "16  <Sequential name=sequential_57, built=True>  \n",
       "10  <Sequential name=sequential_51, built=True>  \n",
       "1   <Sequential name=sequential_29, built=True>  \n",
       "2   <Sequential name=sequential_30, built=True>  \n",
       "11  <Sequential name=sequential_52, built=True>  \n",
       "7   <Sequential name=sequential_45, built=True>  \n",
       "6   <Sequential name=sequential_44, built=True>  \n",
       "4   <Sequential name=sequential_32, built=True>  \n",
       "13  <Sequential name=sequential_54, built=True>  \n",
       "8   <Sequential name=sequential_46, built=True>  \n",
       "17  <Sequential name=sequential_58, built=True>  \n",
       "9   <Sequential name=sequential_47, built=True>  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_batch_size_results = pd.DataFrame(batch_size_results)\n",
    "\n",
    "df_batch_size_results.sort_values(by='MSE').head(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 10\n",
      "Epoch 1/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 20ms/step - loss: 0.6064 - val_loss: 0.2538\n",
      "Epoch 2/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 0.2506 - val_loss: 0.2317\n",
      "Epoch 3/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 0.2458 - val_loss: 0.2366\n",
      "Epoch 4/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 0.2386 - val_loss: 0.2258\n",
      "Epoch 5/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 0.2292 - val_loss: 0.2155\n",
      "Epoch 6/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 0.2265 - val_loss: 0.2400\n",
      "Epoch 7/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 0.2159 - val_loss: 0.2221\n",
      "Epoch 8/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 0.2145 - val_loss: 0.2160\n",
      "Epoch 9/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 0.2165 - val_loss: 0.2044\n",
      "Epoch 10/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 0.2067 - val_loss: 0.1963\n",
      "Epoch 11/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - loss: 0.2045 - val_loss: 0.2005\n",
      "Epoch 12/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1831 - val_loss: 0.2037\n",
      "Epoch 13/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.2028 - val_loss: 0.1933\n",
      "Epoch 14/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.1850 - val_loss: 0.1825\n",
      "Epoch 15/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1818 - val_loss: 0.1856\n",
      "Epoch 16/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1815 - val_loss: 0.1715\n",
      "Epoch 17/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.1697 - val_loss: 0.1712\n",
      "Epoch 18/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1728 - val_loss: 0.1770\n",
      "Epoch 19/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.1658 - val_loss: 0.1763\n",
      "Epoch 20/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1636 - val_loss: 0.1532\n",
      "Epoch 21/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1655 - val_loss: 0.1603\n",
      "Epoch 22/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1645 - val_loss: 0.1492\n",
      "Epoch 23/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1501 - val_loss: 0.1655\n",
      "Epoch 24/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.1540 - val_loss: 0.1467\n",
      "Epoch 25/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1451 - val_loss: 0.1468\n",
      "Epoch 26/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1454 - val_loss: 0.1466\n",
      "Epoch 27/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1493 - val_loss: 0.1547\n",
      "Epoch 28/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1389 - val_loss: 0.1494\n",
      "Epoch 29/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.1400 - val_loss: 0.1599\n",
      "Epoch 30/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1443 - val_loss: 0.1479\n",
      "Epoch 31/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1408 - val_loss: 0.1428\n",
      "Epoch 32/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.1398 - val_loss: 0.1448\n",
      "Epoch 33/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1377 - val_loss: 0.1493\n",
      "Epoch 34/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.1356 - val_loss: 0.1431\n",
      "Epoch 35/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1330 - val_loss: 0.1458\n",
      "Epoch 36/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.1350 - val_loss: 0.1579\n",
      "Epoch 37/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1359 - val_loss: 0.1483\n",
      "Epoch 38/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1303 - val_loss: 0.1518\n",
      "Epoch 39/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.1280 - val_loss: 0.1445\n",
      "Epoch 40/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - loss: 0.1334 - val_loss: 0.1471\n",
      "Epoch 41/150\n",
      "\u001b[1m1068/1068\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - loss: 0.1283 - val_loss: 0.1465\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1496\n",
      "Batch size: 16\n",
      "Epoch 1/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - loss: 0.7501 - val_loss: 0.2800\n",
      "Epoch 2/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - loss: 0.2802 - val_loss: 0.2505\n",
      "Epoch 3/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.2677 - val_loss: 0.2382\n",
      "Epoch 4/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.2491 - val_loss: 0.2455\n",
      "Epoch 5/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.2341 - val_loss: 0.2281\n",
      "Epoch 6/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.2248 - val_loss: 0.2189\n",
      "Epoch 7/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.2217 - val_loss: 0.2260\n",
      "Epoch 8/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.2121 - val_loss: 0.2198\n",
      "Epoch 9/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.2158 - val_loss: 0.2112\n",
      "Epoch 10/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.2066 - val_loss: 0.2061\n",
      "Epoch 11/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.2048 - val_loss: 0.2104\n",
      "Epoch 12/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.2143 - val_loss: 0.2019\n",
      "Epoch 13/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1969 - val_loss: 0.2017\n",
      "Epoch 14/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.2003 - val_loss: 0.1950\n",
      "Epoch 15/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1864 - val_loss: 0.1876\n",
      "Epoch 16/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1856 - val_loss: 0.1892\n",
      "Epoch 17/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1874 - val_loss: 0.1798\n",
      "Epoch 18/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1816 - val_loss: 0.1690\n",
      "Epoch 19/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1715 - val_loss: 0.1680\n",
      "Epoch 20/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - loss: 0.1835 - val_loss: 0.1604\n",
      "Epoch 21/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - loss: 0.1622 - val_loss: 0.1753\n",
      "Epoch 22/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1596 - val_loss: 0.1652\n",
      "Epoch 23/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1659 - val_loss: 0.1620\n",
      "Epoch 24/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1559 - val_loss: 0.1583\n",
      "Epoch 25/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1563 - val_loss: 0.1524\n",
      "Epoch 26/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1436 - val_loss: 0.1551\n",
      "Epoch 27/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1471 - val_loss: 0.1506\n",
      "Epoch 28/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1495 - val_loss: 0.1555\n",
      "Epoch 29/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1439 - val_loss: 0.1507\n",
      "Epoch 30/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1457 - val_loss: 0.1482\n",
      "Epoch 31/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1416 - val_loss: 0.1456\n",
      "Epoch 32/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1405 - val_loss: 0.1432\n",
      "Epoch 33/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1356 - val_loss: 0.1472\n",
      "Epoch 34/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1392 - val_loss: 0.1447\n",
      "Epoch 35/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1384 - val_loss: 0.1432\n",
      "Epoch 36/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1345 - val_loss: 0.1441\n",
      "Epoch 37/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1290 - val_loss: 0.1460\n",
      "Epoch 38/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1329 - val_loss: 0.1467\n",
      "Epoch 39/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1348 - val_loss: 0.1447\n",
      "Epoch 40/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - loss: 0.1304 - val_loss: 0.1428\n",
      "Epoch 41/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1310 - val_loss: 0.1497\n",
      "Epoch 42/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1337 - val_loss: 0.1464\n",
      "Epoch 43/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1340 - val_loss: 0.1492\n",
      "Epoch 44/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1254 - val_loss: 0.1476\n",
      "Epoch 45/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1288 - val_loss: 0.1427\n",
      "Epoch 46/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1245 - val_loss: 0.1471\n",
      "Epoch 47/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1274 - val_loss: 0.1441\n",
      "Epoch 48/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1214 - val_loss: 0.1457\n",
      "Epoch 49/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1250 - val_loss: 0.1455\n",
      "Epoch 50/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1230 - val_loss: 0.1474\n",
      "Epoch 51/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1212 - val_loss: 0.1500\n",
      "Epoch 52/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1168 - val_loss: 0.1509\n",
      "Epoch 53/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1205 - val_loss: 0.1453\n",
      "Epoch 54/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 20ms/step - loss: 0.1172 - val_loss: 0.1466\n",
      "Epoch 55/150\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 21ms/step - loss: 0.1145 - val_loss: 0.1491\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1499\n",
      "Batch size: 32\n",
      "Epoch 1/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 34ms/step - loss: 1.0369 - val_loss: 0.3015\n",
      "Epoch 2/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.2889 - val_loss: 0.2505\n",
      "Epoch 3/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.2542 - val_loss: 0.2270\n",
      "Epoch 4/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.2537 - val_loss: 0.2478\n",
      "Epoch 5/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.2409 - val_loss: 0.2286\n",
      "Epoch 6/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.2311 - val_loss: 0.2230\n",
      "Epoch 7/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.2291 - val_loss: 0.2266\n",
      "Epoch 8/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.2184 - val_loss: 0.2152\n",
      "Epoch 9/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.2190 - val_loss: 0.2323\n",
      "Epoch 10/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.2130 - val_loss: 0.2110\n",
      "Epoch 11/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.2122 - val_loss: 0.2044\n",
      "Epoch 12/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.2067 - val_loss: 0.2291\n",
      "Epoch 13/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.2108 - val_loss: 0.2010\n",
      "Epoch 14/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.2058 - val_loss: 0.2012\n",
      "Epoch 15/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.2059 - val_loss: 0.1984\n",
      "Epoch 16/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.2028 - val_loss: 0.2019\n",
      "Epoch 17/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - loss: 0.1995 - val_loss: 0.2117\n",
      "Epoch 18/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1993 - val_loss: 0.1991\n",
      "Epoch 19/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - loss: 0.1882 - val_loss: 0.1992\n",
      "Epoch 20/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1979 - val_loss: 0.1926\n",
      "Epoch 21/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1913 - val_loss: 0.2072\n",
      "Epoch 22/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1875 - val_loss: 0.2037\n",
      "Epoch 23/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1948 - val_loss: 0.1899\n",
      "Epoch 24/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1885 - val_loss: 0.2011\n",
      "Epoch 25/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1897 - val_loss: 0.1892\n",
      "Epoch 26/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1836 - val_loss: 0.1851\n",
      "Epoch 27/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1836 - val_loss: 0.1877\n",
      "Epoch 28/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1822 - val_loss: 0.1784\n",
      "Epoch 29/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1852 - val_loss: 0.1811\n",
      "Epoch 30/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step - loss: 0.1824 - val_loss: 0.1780\n",
      "Epoch 31/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1793 - val_loss: 0.1734\n",
      "Epoch 32/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1715 - val_loss: 0.1680\n",
      "Epoch 33/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1646 - val_loss: 0.1687\n",
      "Epoch 34/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1631 - val_loss: 0.1634\n",
      "Epoch 35/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1633 - val_loss: 0.1657\n",
      "Epoch 36/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1619 - val_loss: 0.1582\n",
      "Epoch 37/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - loss: 0.1536 - val_loss: 0.1571\n",
      "Epoch 38/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1577 - val_loss: 0.1604\n",
      "Epoch 39/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1549 - val_loss: 0.1532\n",
      "Epoch 40/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1501 - val_loss: 0.1524\n",
      "Epoch 41/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1544 - val_loss: 0.1659\n",
      "Epoch 42/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1474 - val_loss: 0.1594\n",
      "Epoch 43/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - loss: 0.1502 - val_loss: 0.1536\n",
      "Epoch 44/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1443 - val_loss: 0.1565\n",
      "Epoch 45/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1465 - val_loss: 0.1522\n",
      "Epoch 46/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1359 - val_loss: 0.1586\n",
      "Epoch 47/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1483 - val_loss: 0.1510\n",
      "Epoch 48/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1442 - val_loss: 0.1472\n",
      "Epoch 49/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1458 - val_loss: 0.1493\n",
      "Epoch 50/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1414 - val_loss: 0.1512\n",
      "Epoch 51/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1346 - val_loss: 0.1564\n",
      "Epoch 52/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1404 - val_loss: 0.1513\n",
      "Epoch 53/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1364 - val_loss: 0.1498\n",
      "Epoch 54/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1351 - val_loss: 0.1462\n",
      "Epoch 55/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1351 - val_loss: 0.1523\n",
      "Epoch 56/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1372 - val_loss: 0.1453\n",
      "Epoch 57/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1360 - val_loss: 0.1454\n",
      "Epoch 58/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1333 - val_loss: 0.1509\n",
      "Epoch 59/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1309 - val_loss: 0.1512\n",
      "Epoch 60/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1309 - val_loss: 0.1488\n",
      "Epoch 61/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1336 - val_loss: 0.1506\n",
      "Epoch 62/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1319 - val_loss: 0.1501\n",
      "Epoch 63/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1340 - val_loss: 0.1488\n",
      "Epoch 64/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 0.1256 - val_loss: 0.1500\n",
      "Epoch 65/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1242 - val_loss: 0.1537\n",
      "Epoch 66/150\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - loss: 0.1226 - val_loss: 0.1508\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1510\n",
      "Batch size: 64\n",
      "Epoch 1/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - loss: 1.4119 - val_loss: 0.4070\n",
      "Epoch 2/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - loss: 0.3549 - val_loss: 0.2944\n",
      "Epoch 3/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 0.2784 - val_loss: 0.2408\n",
      "Epoch 4/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 0.2476 - val_loss: 0.2374\n",
      "Epoch 5/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 0.2319 - val_loss: 0.2489\n",
      "Epoch 6/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.2397 - val_loss: 0.2467\n",
      "Epoch 7/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 0.2409 - val_loss: 0.2465\n",
      "Epoch 8/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.2330 - val_loss: 0.2178\n",
      "Epoch 9/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 0.2300 - val_loss: 0.2228\n",
      "Epoch 10/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.2221 - val_loss: 0.2101\n",
      "Epoch 11/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 0.2121 - val_loss: 0.2259\n",
      "Epoch 12/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.2137 - val_loss: 0.2083\n",
      "Epoch 13/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 0.2088 - val_loss: 0.2337\n",
      "Epoch 14/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.2070 - val_loss: 0.2200\n",
      "Epoch 15/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 0.2015 - val_loss: 0.2075\n",
      "Epoch 16/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.2015 - val_loss: 0.2221\n",
      "Epoch 17/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 0.2052 - val_loss: 0.2166\n",
      "Epoch 18/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 0.2036 - val_loss: 0.2145\n",
      "Epoch 19/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 0.2063 - val_loss: 0.2051\n",
      "Epoch 20/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.2048 - val_loss: 0.2036\n",
      "Epoch 21/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 0.1985 - val_loss: 0.1966\n",
      "Epoch 22/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 0.2000 - val_loss: 0.2035\n",
      "Epoch 23/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.1923 - val_loss: 0.2395\n",
      "Epoch 24/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 0.2017 - val_loss: 0.1974\n",
      "Epoch 25/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.1922 - val_loss: 0.2006\n",
      "Epoch 26/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 0.1949 - val_loss: 0.1982\n",
      "Epoch 27/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1851 - val_loss: 0.1931\n",
      "Epoch 28/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 0.1905 - val_loss: 0.1980\n",
      "Epoch 29/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 0.1940 - val_loss: 0.1995\n",
      "Epoch 30/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 0.1922 - val_loss: 0.1925\n",
      "Epoch 31/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - loss: 0.1916 - val_loss: 0.1957\n",
      "Epoch 32/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 0.1919 - val_loss: 0.2028\n",
      "Epoch 33/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.1902 - val_loss: 0.1920\n",
      "Epoch 34/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - loss: 0.1899 - val_loss: 0.1995\n",
      "Epoch 35/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.1927 - val_loss: 0.1978\n",
      "Epoch 36/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 0.1889 - val_loss: 0.1879\n",
      "Epoch 37/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - loss: 0.1822 - val_loss: 0.1878\n",
      "Epoch 38/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1846 - val_loss: 0.1875\n",
      "Epoch 39/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.1827 - val_loss: 0.1841\n",
      "Epoch 40/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1863 - val_loss: 0.1969\n",
      "Epoch 41/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.1892 - val_loss: 0.1825\n",
      "Epoch 42/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 0.1793 - val_loss: 0.1853\n",
      "Epoch 43/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 0.1868 - val_loss: 0.1871\n",
      "Epoch 44/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1852 - val_loss: 0.1883\n",
      "Epoch 45/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 0.1765 - val_loss: 0.1884\n",
      "Epoch 46/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - loss: 0.1840 - val_loss: 0.1776\n",
      "Epoch 47/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.1768 - val_loss: 0.1806\n",
      "Epoch 48/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - loss: 0.1735 - val_loss: 0.1764\n",
      "Epoch 49/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1734 - val_loss: 0.1763\n",
      "Epoch 50/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 0.1693 - val_loss: 0.1718\n",
      "Epoch 51/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 0.1733 - val_loss: 0.1676\n",
      "Epoch 52/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.1610 - val_loss: 0.1797\n",
      "Epoch 53/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1748 - val_loss: 0.1691\n",
      "Epoch 54/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - loss: 0.1722 - val_loss: 0.1624\n",
      "Epoch 55/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.1648 - val_loss: 0.1770\n",
      "Epoch 56/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1609 - val_loss: 0.1849\n",
      "Epoch 57/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1667 - val_loss: 0.1703\n",
      "Epoch 58/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - loss: 0.1633 - val_loss: 0.1727\n",
      "Epoch 59/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.1620 - val_loss: 0.1576\n",
      "Epoch 60/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1549 - val_loss: 0.1593\n",
      "Epoch 61/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.1583 - val_loss: 0.1644\n",
      "Epoch 62/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.1579 - val_loss: 0.1589\n",
      "Epoch 63/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - loss: 0.1601 - val_loss: 0.1637\n",
      "Epoch 64/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1546 - val_loss: 0.1590\n",
      "Epoch 65/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - loss: 0.1529 - val_loss: 0.1528\n",
      "Epoch 66/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1580 - val_loss: 0.1530\n",
      "Epoch 67/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.1498 - val_loss: 0.1539\n",
      "Epoch 68/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 0.1524 - val_loss: 0.1529\n",
      "Epoch 69/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - loss: 0.1442 - val_loss: 0.1552\n",
      "Epoch 70/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 0.1441 - val_loss: 0.1519\n",
      "Epoch 71/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.1472 - val_loss: 0.1540\n",
      "Epoch 72/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - loss: 0.1468 - val_loss: 0.1531\n",
      "Epoch 73/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 0.1330 - val_loss: 0.1521\n",
      "Epoch 74/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1420 - val_loss: 0.1512\n",
      "Epoch 75/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1427 - val_loss: 0.1564\n",
      "Epoch 76/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1390 - val_loss: 0.1493\n",
      "Epoch 77/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 0.1350 - val_loss: 0.1486\n",
      "Epoch 78/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.1353 - val_loss: 0.1586\n",
      "Epoch 79/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 0.1360 - val_loss: 0.1502\n",
      "Epoch 80/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - loss: 0.1368 - val_loss: 0.1481\n",
      "Epoch 81/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1342 - val_loss: 0.1468\n",
      "Epoch 82/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1333 - val_loss: 0.1493\n",
      "Epoch 83/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 0.1416 - val_loss: 0.1457\n",
      "Epoch 84/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1318 - val_loss: 0.1519\n",
      "Epoch 85/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 0.1305 - val_loss: 0.1471\n",
      "Epoch 86/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 53ms/step - loss: 0.1322 - val_loss: 0.1484\n",
      "Epoch 87/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1352 - val_loss: 0.1494\n",
      "Epoch 88/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 0.1329 - val_loss: 0.1490\n",
      "Epoch 89/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 0.1305 - val_loss: 0.1504\n",
      "Epoch 90/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 0.1284 - val_loss: 0.1530\n",
      "Epoch 91/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 0.1292 - val_loss: 0.1504\n",
      "Epoch 92/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - loss: 0.1328 - val_loss: 0.1510\n",
      "Epoch 93/150\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 52ms/step - loss: 0.1279 - val_loss: 0.1536\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1511\n",
      "Batch size: 80\n",
      "Epoch 1/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - loss: 1.3798 - val_loss: 0.3139\n",
      "Epoch 2/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.3270 - val_loss: 0.2855\n",
      "Epoch 3/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 58ms/step - loss: 0.2734 - val_loss: 0.2537\n",
      "Epoch 4/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.2509 - val_loss: 0.2305\n",
      "Epoch 5/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - loss: 0.2392 - val_loss: 0.2219\n",
      "Epoch 6/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.2293 - val_loss: 0.2437\n",
      "Epoch 7/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.2235 - val_loss: 0.2274\n",
      "Epoch 8/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - loss: 0.2330 - val_loss: 0.2717\n",
      "Epoch 9/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - loss: 0.2571 - val_loss: 0.2586\n",
      "Epoch 10/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.2271 - val_loss: 0.2203\n",
      "Epoch 11/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.2183 - val_loss: 0.2231\n",
      "Epoch 12/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - loss: 0.2129 - val_loss: 0.2151\n",
      "Epoch 13/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 59ms/step - loss: 0.2180 - val_loss: 0.2108\n",
      "Epoch 14/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - loss: 0.2077 - val_loss: 0.2051\n",
      "Epoch 15/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.2096 - val_loss: 0.2269\n",
      "Epoch 16/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.2111 - val_loss: 0.2211\n",
      "Epoch 17/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.2088 - val_loss: 0.2064\n",
      "Epoch 18/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - loss: 0.1982 - val_loss: 0.2148\n",
      "Epoch 19/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - loss: 0.2073 - val_loss: 0.2055\n",
      "Epoch 20/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 59ms/step - loss: 0.2017 - val_loss: 0.2024\n",
      "Epoch 21/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1965 - val_loss: 0.2003\n",
      "Epoch 22/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.1936 - val_loss: 0.1988\n",
      "Epoch 23/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1993 - val_loss: 0.2065\n",
      "Epoch 24/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - loss: 0.2136 - val_loss: 0.2030\n",
      "Epoch 25/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1969 - val_loss: 0.1921\n",
      "Epoch 26/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1881 - val_loss: 0.1979\n",
      "Epoch 27/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - loss: 0.1956 - val_loss: 0.1978\n",
      "Epoch 28/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - loss: 0.1904 - val_loss: 0.2327\n",
      "Epoch 29/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1902 - val_loss: 0.1963\n",
      "Epoch 30/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.1902 - val_loss: 0.1924\n",
      "Epoch 31/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - loss: 0.1846 - val_loss: 0.1915\n",
      "Epoch 32/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 59ms/step - loss: 0.1943 - val_loss: 0.1986\n",
      "Epoch 33/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1921 - val_loss: 0.1998\n",
      "Epoch 34/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1908 - val_loss: 0.1987\n",
      "Epoch 35/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1857 - val_loss: 0.2066\n",
      "Epoch 36/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1940 - val_loss: 0.1991\n",
      "Epoch 37/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1874 - val_loss: 0.1874\n",
      "Epoch 38/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - loss: 0.1866 - val_loss: 0.1876\n",
      "Epoch 39/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1879 - val_loss: 0.1869\n",
      "Epoch 40/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - loss: 0.1842 - val_loss: 0.2083\n",
      "Epoch 41/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - loss: 0.1859 - val_loss: 0.1828\n",
      "Epoch 42/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - loss: 0.1851 - val_loss: 0.1826\n",
      "Epoch 43/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.1856 - val_loss: 0.1913\n",
      "Epoch 44/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1922 - val_loss: 0.1842\n",
      "Epoch 45/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.1892 - val_loss: 0.1855\n",
      "Epoch 46/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - loss: 0.1784 - val_loss: 0.1837\n",
      "Epoch 47/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.1782 - val_loss: 0.1906\n",
      "Epoch 48/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.1773 - val_loss: 0.1838\n",
      "Epoch 49/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1745 - val_loss: 0.1799\n",
      "Epoch 50/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1731 - val_loss: 0.1813\n",
      "Epoch 51/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - loss: 0.1711 - val_loss: 0.1760\n",
      "Epoch 52/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1888 - val_loss: 0.1820\n",
      "Epoch 53/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - loss: 0.1869 - val_loss: 0.1753\n",
      "Epoch 54/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.1727 - val_loss: 0.1839\n",
      "Epoch 55/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - loss: 0.1722 - val_loss: 0.1718\n",
      "Epoch 56/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1731 - val_loss: 0.1693\n",
      "Epoch 57/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1736 - val_loss: 0.1705\n",
      "Epoch 58/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - loss: 0.1634 - val_loss: 0.1735\n",
      "Epoch 59/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.1668 - val_loss: 0.1642\n",
      "Epoch 60/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 63ms/step - loss: 0.1630 - val_loss: 0.1647\n",
      "Epoch 61/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - loss: 0.1628 - val_loss: 0.1627\n",
      "Epoch 62/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.1599 - val_loss: 0.1633\n",
      "Epoch 63/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1718 - val_loss: 0.1640\n",
      "Epoch 64/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1594 - val_loss: 0.1649\n",
      "Epoch 65/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1562 - val_loss: 0.1626\n",
      "Epoch 66/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1503 - val_loss: 0.1623\n",
      "Epoch 67/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.1542 - val_loss: 0.1608\n",
      "Epoch 68/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1594 - val_loss: 0.1591\n",
      "Epoch 69/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1557 - val_loss: 0.1607\n",
      "Epoch 70/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1584 - val_loss: 0.1591\n",
      "Epoch 71/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1538 - val_loss: 0.1553\n",
      "Epoch 72/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - loss: 0.1512 - val_loss: 0.1620\n",
      "Epoch 73/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1534 - val_loss: 0.1591\n",
      "Epoch 74/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1495 - val_loss: 0.1672\n",
      "Epoch 75/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - loss: 0.1454 - val_loss: 0.1691\n",
      "Epoch 76/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.1495 - val_loss: 0.1532\n",
      "Epoch 77/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - loss: 0.1437 - val_loss: 0.1556\n",
      "Epoch 78/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 59ms/step - loss: 0.1508 - val_loss: 0.1554\n",
      "Epoch 79/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - loss: 0.1447 - val_loss: 0.1514\n",
      "Epoch 80/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1455 - val_loss: 0.1592\n",
      "Epoch 81/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - loss: 0.1422 - val_loss: 0.1511\n",
      "Epoch 82/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1468 - val_loss: 0.1526\n",
      "Epoch 83/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - loss: 0.1437 - val_loss: 0.1499\n",
      "Epoch 84/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - loss: 0.1395 - val_loss: 0.1507\n",
      "Epoch 85/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - loss: 0.1445 - val_loss: 0.1503\n",
      "Epoch 86/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 67ms/step - loss: 0.1421 - val_loss: 0.1551\n",
      "Epoch 87/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1368 - val_loss: 0.1479\n",
      "Epoch 88/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - loss: 0.1381 - val_loss: 0.1517\n",
      "Epoch 89/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - loss: 0.1370 - val_loss: 0.1489\n",
      "Epoch 90/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1467 - val_loss: 0.1476\n",
      "Epoch 91/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 59ms/step - loss: 0.1356 - val_loss: 0.1543\n",
      "Epoch 92/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1429 - val_loss: 0.1509\n",
      "Epoch 93/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1389 - val_loss: 0.1557\n",
      "Epoch 94/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - loss: 0.1415 - val_loss: 0.1562\n",
      "Epoch 95/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 60ms/step - loss: 0.1455 - val_loss: 0.1513\n",
      "Epoch 96/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 65ms/step - loss: 0.1326 - val_loss: 0.1509\n",
      "Epoch 97/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - loss: 0.1350 - val_loss: 0.1537\n",
      "Epoch 98/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1428 - val_loss: 0.1511\n",
      "Epoch 99/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 63ms/step - loss: 0.1304 - val_loss: 0.1493\n",
      "Epoch 100/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 62ms/step - loss: 0.1345 - val_loss: 0.1516\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.1547\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = 2\n",
    "neurons = 96\n",
    "epochs = 150\n",
    "batch_size = [10, 16, 32, 64, 80]\n",
    "\n",
    "for b in batch_size:\n",
    "    print(f\"Batch size: {b}\"), \n",
    "    regressor, mse = initModel(hidden_layers, neurons, epochs, b)\n",
    "    batch_size_results.append({'MSE': mse, 'Hidden Layers': hidden_layers, 'Neurons': neurons, 'Batch Size' : b, 'Model': regressor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 80\n",
      "Epoch 1/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 63ms/step - loss: 1.6689 - val_loss: 0.5404\n",
      "Epoch 2/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - loss: 0.5501 - val_loss: 0.5205\n",
      "Epoch 3/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 0.5020 - val_loss: 0.5185\n",
      "Epoch 4/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - loss: 0.4840 - val_loss: 0.4385\n",
      "Epoch 5/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 0.3929 - val_loss: 0.3588\n",
      "Epoch 6/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - loss: 0.3293 - val_loss: 0.3584\n",
      "Epoch 7/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 59ms/step - loss: 0.2945 - val_loss: 0.2676\n",
      "Epoch 8/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - loss: 0.2544 - val_loss: 0.2623\n",
      "Epoch 9/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - loss: 0.2468 - val_loss: 0.2429\n",
      "Epoch 10/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 0.2325 - val_loss: 0.2352\n",
      "Epoch 11/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 0.2293 - val_loss: 0.2934\n",
      "Epoch 12/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - loss: 0.2545 - val_loss: 0.2237\n",
      "Epoch 13/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 0.2345 - val_loss: 0.2201\n",
      "Epoch 14/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - loss: 0.2294 - val_loss: 0.2221\n",
      "Epoch 15/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 0.2167 - val_loss: 0.2216\n",
      "Epoch 16/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - loss: 0.2126 - val_loss: 0.2218\n",
      "Epoch 17/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - loss: 0.2112 - val_loss: 0.2146\n",
      "Epoch 18/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - loss: 0.2200 - val_loss: 0.2087\n",
      "Epoch 19/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - loss: 0.2129 - val_loss: 0.2195\n",
      "Epoch 20/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 59ms/step - loss: 0.2147 - val_loss: 0.2212\n",
      "Epoch 21/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - loss: 0.2080 - val_loss: 0.2182\n",
      "Epoch 22/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 58ms/step - loss: 0.2092 - val_loss: 0.2176\n",
      "Epoch 23/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 0.2162 - val_loss: 0.2084\n",
      "Epoch 24/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 0.2162 - val_loss: 0.2115\n",
      "Epoch 25/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 0.2116 - val_loss: 0.2050\n",
      "Epoch 26/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 0.2057 - val_loss: 0.2125\n",
      "Epoch 27/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - loss: 0.1994 - val_loss: 0.2069\n",
      "Epoch 28/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 58ms/step - loss: 0.2106 - val_loss: 0.2064\n",
      "Epoch 29/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 58ms/step - loss: 0.2076 - val_loss: 0.2248\n",
      "Epoch 30/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 0.2094 - val_loss: 0.2053\n",
      "Epoch 31/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - loss: 0.2183 - val_loss: 0.2241\n",
      "Epoch 32/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 58ms/step - loss: 0.1992 - val_loss: 0.2147\n",
      "Epoch 33/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - loss: 0.2073 - val_loss: 0.2098\n",
      "Epoch 34/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - loss: 0.2036 - val_loss: 0.2081\n",
      "Epoch 35/150\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 55ms/step - loss: 0.2014 - val_loss: 0.2136\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.2025\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = 1\n",
    "neurons = 96\n",
    "epochs = 150\n",
    "batch_size = [80]\n",
    "\n",
    "for b in batch_size:\n",
    "    print(f\"Batch size: {b}\"), \n",
    "    regressor, mse = initModel(hidden_layers, neurons, epochs, b)\n",
    "    batch_size_results.append({'MSE': mse, 'Hidden Layers': hidden_layers, 'Neurons': neurons, 'Batch Size' : b, 'Model': regressor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>Hidden Layers</th>\n",
       "      <th>Neurons</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.140007</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_31, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.140166</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;Sequential name=sequential_55, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142031</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;Sequential name=sequential_28, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.142381</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_53, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.142513</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;Sequential name=sequential_43, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.142859</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_56, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.142868</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_60, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.142949</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;Sequential name=sequential_59, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.143188</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_57, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.143350</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;Sequential name=sequential_51, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.144116</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_29, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.144212</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_30, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.144917</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_52, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.145264</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_45, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.145311</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>32</td>\n",
       "      <td>&lt;Sequential name=sequential_61, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.145682</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;Sequential name=sequential_44, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.146106</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_62, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.147124</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>&lt;Sequential name=sequential_32, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.148008</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_54, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.148048</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>80</td>\n",
       "      <td>&lt;Sequential name=sequential_63, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.150377</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_46, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.165816</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;Sequential name=sequential_58, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.191249</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>&lt;Sequential name=sequential_47, built=True&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.205674</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>80</td>\n",
       "      <td>&lt;Sequential name=sequential_65, built=True&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MSE  Hidden Layers  Neurons  Batch Size  \\\n",
       "3   0.140007              1       80          64   \n",
       "14  0.140166              1       96          10   \n",
       "0   0.142031              1       80          10   \n",
       "12  0.142381              1       80          32   \n",
       "5   0.142513              2       80          10   \n",
       "15  0.142859              1       96          16   \n",
       "19  0.142868              2       96          16   \n",
       "18  0.142949              2       96          10   \n",
       "16  0.143188              1       96          32   \n",
       "10  0.143350              1       80          10   \n",
       "1   0.144116              1       80          16   \n",
       "2   0.144212              1       80          32   \n",
       "11  0.144917              1       80          16   \n",
       "7   0.145264              2       80          32   \n",
       "20  0.145311              2       96          32   \n",
       "6   0.145682              2       80          16   \n",
       "21  0.146106              2       96          64   \n",
       "4   0.147124              1       80          80   \n",
       "13  0.148008              1       80          64   \n",
       "22  0.148048              2       96          80   \n",
       "8   0.150377              2       80          64   \n",
       "17  0.165816              1       96          64   \n",
       "9   0.191249              2       80          80   \n",
       "23  0.205674              1       96          80   \n",
       "\n",
       "                                          Model  \n",
       "3   <Sequential name=sequential_31, built=True>  \n",
       "14  <Sequential name=sequential_55, built=True>  \n",
       "0   <Sequential name=sequential_28, built=True>  \n",
       "12  <Sequential name=sequential_53, built=True>  \n",
       "5   <Sequential name=sequential_43, built=True>  \n",
       "15  <Sequential name=sequential_56, built=True>  \n",
       "19  <Sequential name=sequential_60, built=True>  \n",
       "18  <Sequential name=sequential_59, built=True>  \n",
       "16  <Sequential name=sequential_57, built=True>  \n",
       "10  <Sequential name=sequential_51, built=True>  \n",
       "1   <Sequential name=sequential_29, built=True>  \n",
       "2   <Sequential name=sequential_30, built=True>  \n",
       "11  <Sequential name=sequential_52, built=True>  \n",
       "7   <Sequential name=sequential_45, built=True>  \n",
       "20  <Sequential name=sequential_61, built=True>  \n",
       "6   <Sequential name=sequential_44, built=True>  \n",
       "21  <Sequential name=sequential_62, built=True>  \n",
       "4   <Sequential name=sequential_32, built=True>  \n",
       "13  <Sequential name=sequential_54, built=True>  \n",
       "22  <Sequential name=sequential_63, built=True>  \n",
       "8   <Sequential name=sequential_46, built=True>  \n",
       "17  <Sequential name=sequential_58, built=True>  \n",
       "9   <Sequential name=sequential_47, built=True>  \n",
       "23  <Sequential name=sequential_65, built=True>  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_batch_size_results = pd.DataFrame(batch_size_results)\n",
    "\n",
    "df_batch_size_results.sort_values(by='MSE').head(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_sorted = df_batch_size_results.sort_values(by=['Hidden Layers', 'Neurons', 'Batch Size'])\n",
    "\n",
    "# Define the combinations of Neurons and Hidden Layers\n",
    "combinations = [\n",
    "    {'Neurons': 80, 'Hidden Layers': 1},\n",
    "    {'Neurons': 96, 'Hidden Layers': 1},\n",
    "    {'Neurons': 80, 'Hidden Layers': 2},\n",
    "    {'Neurons': 96, 'Hidden Layers': 2}\n",
    "]\n",
    "\n",
    "# Plot each combination separately\n",
    "for combination in combinations:\n",
    "    neurons_value = combination['Neurons']\n",
    "    hidden_layers_value = combination['Hidden Layers']\n",
    "    \n",
    "    # Filter DataFrame for the current combination\n",
    "    df_filtered = df_sorted[(df_sorted['Neurons'] == neurons_value) & (df_sorted['Hidden Layers'] == hidden_layers_value)]\n",
    "    \n",
    "    # Plot the filtered data\n",
    "    plt.plot(df_filtered['Batch Size'], df_filtered['MSE'], label=f'Neurons={neurons_value}, Hidden Layers={hidden_layers_value}')\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "# plt.title('Batch Size vs MSE for Different Combinations of Neurons and Hidden Layers')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in batch_size_results:\n",
    "    row['Model'].save(str(row['Neurons']) + '_neurons_' + str(row['Hidden Layers']) + '_layers_' + str(row['Batch Size']) + '_Batch Size_' + '.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_31\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_31\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_61 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)             │        \u001b[38;5;34m27,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m81\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,845</span> (319.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m81,845\u001b[0m (319.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,281</span> (106.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,281\u001b[0m (106.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,564</span> (213.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m54,564\u001b[0m (213.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = min(batch_size_results, key=lambda x: x['MSE'])['Model']\n",
    "best_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27281"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │         \u001b[38;5;34m1,344\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,421</span> (40.71 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,421\u001b[0m (40.71 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,473</span> (13.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,473\u001b[0m (13.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,948</span> (27.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6,948\u001b[0m (27.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "worst_model = max(results, key=lambda x: x['MSE'])['Model']\n",
    "worst_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 4)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
