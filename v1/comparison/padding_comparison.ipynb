{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding Comparison\n",
    "\n",
    "According to Reddy and Reddy (2019), there is little difference in performance between pre- and post padding in LSTMs, unlike with CNNs. This file is a more comprehensive comparison, creating models for upstream, downstream, and split padding. All input data is used in these models except for spacer sequences ('spacs' column) with lengths other than 16, 17, and 18. These other sequences have been synthetically developed and vary with a length from 0 to 31.\n",
    "\n",
    "Padding makes all the inputs equal in length by adding layers of zeros or other \"filler\" data outside the actual data in an input matrix. The primary purpose of padding is to preserve the spatial size of the input so that the output after applying filters (kernels) remains the same size or to adjust it according to the desired output dimensions.\n",
    "\n",
    "In LSTM, padding is applied before performing the convolution operation. When a filter scans the input data, padding ensures that the filter properly covers the border areas, allowing for more accurate feature extraction. This is particularly important in deep learning, as it allows the network to learn from the entire dataset without bias towards the center of the images.\n",
    "\n",
    "The amount of padding needed depends on the size of the filter (also known as the kernel) and the desired output size. For a filter of size FxF and input size NxN, to achieve 'same' padding, one would typically add (F-1)/2 rows of zeros on both the top and bottom of the input and the same number of columns of zeros on the left and right sides.\n",
    "\n",
    "https://deepai.org/machine-learning-glossary-and-terms/padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset into a pandas data frame\n",
    "\n",
    "df = pd.read_csv('41467_2022_32829_MOESM5_ESM.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All input and output data\n",
    "\n",
    "X = df[['UP', 'h35', 'spacs', 'h10', 'disc', 'ITR']]\n",
    "y = df['Observed log(TX/Txref)']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores the various input approaches\n",
    "X_dict = {}\n",
    "\n",
    "# stores split training/testing\n",
    "train_test = {}\n",
    "\n",
    "# stores the results\n",
    "results = {}\n",
    "\n",
    "# stores the models\n",
    "models = {}\n",
    "\n",
    "# stores the model history\n",
    "model_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for random search\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def build_model(current_model):\n",
    "    # Define RNN model architecture\n",
    "    models[current_model] = Sequential()\n",
    "    models[current_model].add(LSTM(64, input_shape=X_dict[current_model].shape[1:])) # dynamically generated input shape based on X data\n",
    "    models[current_model].add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    models[current_model].compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Early stopping to prevent overfitting\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Train the model\n",
    "    history = models[current_model].fit(train_test[current_model]['X_train'],\n",
    "                                    train_test[current_model]['y_train'],\n",
    "                                    epochs=150,\n",
    "                                    batch_size=32,\n",
    "                                    validation_data=(X_test, y_test),\n",
    "                                    callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss = models[current_model].evaluate(train_test[current_model]['X_test'], train_test[current_model]['y_test'])\n",
    "\n",
    "    return models[current_model], loss, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all rows with spacer sequences that are not 16-18 nucleotides long\n",
    "\n",
    "\n",
    "_df = df[(df['spacs'].str.len() >= 16) & (df['spacs'].str.len() <= 18)]\n",
    "\n",
    "X = _df[['UP', 'h35', 'spacs', 'h10', 'disc', 'ITR']]\n",
    "y = _df['Observed log(TX/Txref)']\n",
    "\n",
    "print(f'Removed {df.shape[0] - _df.shape[0]} rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to one-hot encode DNA sequences\n",
    "\n",
    "def padded_one_hot_encode(sequence):\n",
    "    mapping = {'A': [1,0,0,0,0], 'C': [0,1,0,0,0], 'G': [0,0,1,0,0], 'T': [0,0,0,1,0], '0': [0,0,0,0,1]}\n",
    "    encoding = []\n",
    "    for nucleotide in sequence:\n",
    "         encoding += [mapping[nucleotide]]\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upstream Padding\n",
    "Add padding upstream (before) each sequence to standardize the length, then concatenate the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_padding_full = {}\n",
    "\n",
    "for col in X.columns:\n",
    "    max_len = X[col].apply(len).max()\n",
    "    upstream_padding_full[col] = np.array([padded_one_hot_encode('0' * (max_len - len(seq)) + seq) for seq in X[col]])\n",
    "\n",
    "# Concatenate the one-hot encoded, upstream-padded sequences\n",
    "X_dict['upstream_padding_full'] = np.concatenate([upstream_padding_full[col] for col in X.columns], axis=1)\n",
    "X_dict['upstream_padding_full'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data in training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dict['upstream_padding_full'], y, test_size=0.2, random_state=1, shuffle=True)\n",
    "train_test['upstream_padding_full'] = {'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to build the model, save the model, and store the results\n",
    "\n",
    "m = 'upstream_padding_full'\n",
    "\n",
    "models[m], results[m], model_history[m] = build_model(m)\n",
    "models[m].save(m + '.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream Padding\n",
    "Add padding downstream (after) each sequence to standardize the length, then concatenate the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downstream_padding_full = {}\n",
    "\n",
    "for col in X.columns:\n",
    "    max_len = X[col].apply(len).max()\n",
    "    downstream_padding_full[col] = np.array([padded_one_hot_encode(seq + '0' * (max_len - len(seq))) for seq in X[col]])\n",
    "\n",
    "# Concatenate the one-hot encoded, upstream-padded sequences\n",
    "X_dict['downstream_padding_full'] = np.concatenate([downstream_padding_full[col] for col in X.columns], axis=1)\n",
    "X_dict['downstream_padding_full'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data in training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dict['downstream_padding_full'], y, test_size=0.2, random_state=1, shuffle=True)\n",
    "train_test['downstream_padding_full'] = {'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to build the model, save the model, and store the results\n",
    "\n",
    "m = 'downstream_padding_full'\n",
    "\n",
    "models[m], results[m], model_history[m] = build_model(m)\n",
    "models[m].save(m + '.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Padding\n",
    "Add half the padding upstream (before) and half the padding downstream (after) for each sequence to standardize the length, then concatenate the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_padding_full = {}\n",
    "\n",
    "for col in X.columns:\n",
    "    max_len = X[col].apply(len).max()\n",
    "    split_padding_full[col] = np.array([padded_one_hot_encode('0' * ((max_len - len(seq)) // 2) +\n",
    "                                                              seq + '0' * ((max_len - len(seq) + 1) // 2)) for seq in X[col]])\n",
    "\n",
    "# Concatenate the one-hot encoded, upstream-padded sequences\n",
    "X_dict['split_padding_full'] = np.concatenate([split_padding_full[col] for col in X.columns], axis=1)\n",
    "X_dict['split_padding_full'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data in training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dict['split_padding_full'], y, test_size=0.2, random_state=1, shuffle=True)\n",
    "train_test['split_padding_full'] = {'X_train': X_train, 'X_test': X_test, 'y_train': y_train, 'y_test': y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to build the model, save the model, and store the results\n",
    "\n",
    "m = 'split_padding_full'\n",
    "\n",
    "models[m], results[m], model_history[m] = build_model(m)\n",
    "models[m].save(m + '.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
