{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desciption\n",
    "\n",
    "### Architecture\n",
    "\n",
    "Model chnages: higher TX/expression is now higher prediction.\n",
    "\n",
    "This version optimizes the process of training/testing and uses hyperparameter tuning. It uses a similar architecture to CNN_5_0. It does not include augmented data, just takes the data from La Fleur's supplemental materials including:\n",
    "- La Fleur et al (and De Novo Designs)\n",
    "- Urtecho et al\n",
    "- Hossain et al\n",
    "- Yu et al\n",
    "- Lagator (36N, Pl, and Pr)\n",
    "- Anderson Series\n",
    "\n",
    "We onehot encode each basepair and pad the whole sequence. Because we use a CNN which is designed to identify \"features,\" the input promoter can be any length (with padding) and the model will be able to accurately predict the expression.\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "\n",
    "A hyperparameter is a parameter that can be set in order to define any configurable part of a model's learning process. For this CNN, the architecture hyperparameters we optimize are:\n",
    "- Number of Layers\n",
    "- Number of Filters/Kernels\n",
    "- Filter Size\n",
    "- Stride\n",
    "- Padding\n",
    "- Pooling Size\n",
    "- Pooling Type\n",
    "- Activation Functions\n",
    "\n",
    "The training hyperparameters we optimize are:\n",
    "- Learning Rate\n",
    "- Learning Rate Decay\n",
    "- Batch Size\n",
    "- Number of Epochs\n",
    "\n",
    "The regularization hyperparameters we optimize are:\n",
    "- Dropout Rate\n",
    "- Weight Decay\n",
    "- Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CNN_6_0 as parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../Models/CNN_6_0.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = parent.load_features('../Data/Train Test/train_data.csv')\n",
    "X_test, y_test = parent.load_features('../Data/Train Test/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = parent.build_cnn_model(X_train.shape[1:])\n",
    "history = parent.train_model(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = parent.load_and_predict(model_path, X_test)\n",
    "\n",
    "mse, rmse, mae, r2 = parent.calc_metrics(y_test, y_pred)\n",
    "\n",
    "print('MSE: ', mse)\n",
    "print('RMSE: ', rmse)\n",
    "print('MAE: ', mae)\n",
    "print('R2: ', r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
